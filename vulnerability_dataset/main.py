import logging
from typing import List, Tuple

from .config import settings
from .database.db_manager import DatabaseManager
from .git.git_manager_parse_LLM import GitManager, extract_change_line
from .data_processing.cleaner import DataCleaner
from .data_processing.exporter import DataExporter
from .utils.logger import setup_logging
from .config.settings import BATCH_SIZE

logger = setup_logging()

def process_vulnerability(git_manager: GitManager, db_manager: DatabaseManager,
                          commit_hash: str, project: str) -> None:
    """Process a single vulnerability."""
    try:
        # Get patch and analyze it
        patch = git_manager.get_patch(project, commit_hash)
        if not patch:
            logger.warning(f"No patch found for {commit_hash} in {project}")
            return

        patch_info = git_manager.analyze_patch(patch)
        description = git_manager.get_commit_description(project, commit_hash)

        vulnerable_code = []
        patched_code = []

        # Process each changed file
        for file_path in patch_info['files_changed']:
            if patch_info.get('single_line_change'):
                hunk_header = patch_info.get('hunk_header', "")
                change_line = extract_change_line(hunk_header)
                vuln_full = git_manager.get_file_content(project, commit_hash, file_path, parent=True)
                patch_full = git_manager.get_file_content(project, commit_hash, file_path)
                if change_line != -1:
                    vuln_func = git_manager.extract_changed_function(vuln_full, change_line) if vuln_full else None
                    patch_func = git_manager.extract_changed_function(patch_full, change_line) if patch_full else None
                else:
                    vuln_func = vuln_full
                    patch_func = patch_full
                if vuln_func:
                    vulnerable_code.append(f"// File: {file_path}\n{vuln_func}")
                if patch_func:
                    patched_code.append(f"// File: {file_path}\n{patch_func}")
            else:
                vuln_code = git_manager.extract_vulnerable_code(project, commit_hash, file_path)
                patch_code = git_manager.extract_patched_code(project, commit_hash, file_path)
                if vuln_code:
                    vulnerable_code.append(f"// File: {file_path}\n{vuln_code}")
                if patch_code:
                    patched_code.append(f"// File: {file_path}\n{patch_code}")

        metadata = {
            'num_files_changed': patch_info['functions_changed'],  # or len(patch_info['files_changed'])
            'num_functions_changed': patch_info['functions_changed'],
            'num_lines_added': patch_info['lines_added'],
            'num_lines_deleted': patch_info['lines_deleted'],
            'description': description
        }

        db_manager.update_code_blocks(
            commit_hash=commit_hash,
            project=project,
            vulnerable_code='\n'.join(vulnerable_code),
            patched_code='\n'.join(patched_code),
            metadata=metadata
        )

        logger.info(f"Processed {commit_hash} in {project}")

    except Exception as e:
        logger.error(f"Error processing {commit_hash} in {project}: {e}")

def main():
    """Main execution function."""
    try:
        # Initialize managers
        db_manager = DatabaseManager()
        git_manager = GitManager()
        data_cleaner = DataCleaner()
        data_exporter = DataExporter()
        
        # Create and initialize database
        logger.info("Creating database...")
        db_manager.create_database()
        
        # Clean data
        logger.info("Cleaning data...")
        initial_count, final_count = data_cleaner.remove_duplicates()
        logger.info(f"Removed {initial_count - final_count} duplicates")
        
        # Retrieve vulnerabilities from the database
        with db_manager._get_connection() as (conn, cursor):
            cursor.execute("SELECT COMMIT_HASH, PROJECT FROM vulnerabilities")
            vulnerabilities: List[Tuple[str, str]] = cursor.fetchall()
        
        logger.info(f"Found {len(vulnerabilities)} vulnerabilities to process")
        
        # Define a batch size (adjust as needed)
        batch_size = BATCH_SIZE
        
        # Process vulnerabilities in batches sequentially
        for i in range(0, len(vulnerabilities), batch_size):
            batch = vulnerabilities[i:i+batch_size]
            for commit_hash, project in batch:
                process_vulnerability(git_manager, db_manager, commit_hash, project)
        
        # Export results
        logger.info("Exporting results...")
        data_exporter.export_to_csv('vulnerabilities.csv')
        
        # Print statistics
        stats = db_manager.get_statistics()
        logger.info("\nFinal Statistics:")
        for project, project_stats in stats.items():
            logger.info(f"\n{project}:")
            for key, value in project_stats.items():
                logger.info(f"  {key}: {value}")
        
    except Exception as e:
        logger.error(f"Error in main execution: {e}")
        raise
    
    # Retrieve vulnerabilities from the database
    with db_manager._get_connection() as (conn, cursor):
        cursor.execute("SELECT COMMIT_HASH, PROJECT FROM vulnerabilities")
        vulnerabilities: List[Tuple[str, str]] = cursor.fetchall()


if __name__ == "__main__":
    main()
