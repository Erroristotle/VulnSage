{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "class GitInteraction:\n",
    "    def __init__(self, repo_path):\n",
    "        self.repo_path = repo_path\n",
    "\n",
    "    def get_file_at_commit(self, commit_hash, file_path):\n",
    "        \"\"\"Get the contents of a file at a specific commit.\"\"\"\n",
    "        try:\n",
    "            command = [\"git\", \"show\", f\"{commit_hash}:{file_path}\"]\n",
    "            result = subprocess.run(\n",
    "                command,\n",
    "                cwd=self.repo_path,\n",
    "                text=True,\n",
    "                capture_output=True,\n",
    "                check=True,\n",
    "                encoding='utf-8',\n",
    "                errors='ignore'\n",
    "            )\n",
    "            return result.stdout\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error getting file at commit: {commit_hash} using command: {command}\")\n",
    "            print(e.output)\n",
    "            return None\n",
    "\n",
    "    def get_patch_of_commit(self, commit_hash):\n",
    "        \"\"\"Fetch the patch of a specific commit from the GitHub URL.\"\"\"\n",
    "        url = f\"https://github.com/mozilla/gecko-dev/commit/{commit_hash}.patch\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            patch_text = response.text\n",
    "            return patch_text\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching patch from URL: {url}\")\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    def fetch_pre_fix_vulnerable_code(self, commit_hash, file_path):\n",
    "        \"\"\"Fetch vulnerable code segments from the commit prior to the fixing commit.\"\"\"\n",
    "        parent_commit_hash = f\"{commit_hash}^\"\n",
    "        return self.get_file_at_commit(parent_commit_hash, file_path)\n",
    "\n",
    "    def fetch_fixed_code(self, commit_hash, file_path):\n",
    "        \"\"\"Fetch patched code segments from the commit.\"\"\"\n",
    "        return self.get_file_at_commit(commit_hash, file_path)    \n",
    "    \n",
    "    def extract_function_signatures(self, code):\n",
    "        \"\"\"Extract function signatures from the code.\"\"\"\n",
    "        pattern = r'\\b(?:(?:static|struct\\s+\\w+\\s*\\*?)\\s+)*\\w+\\s+\\**\\w+\\s*\\([^)]*\\)\\s*\\{'\n",
    "        matches = re.findall(pattern, code, re.MULTILINE)\n",
    "        function_signatures = [match.strip() for match in matches]\n",
    "        return function_signatures\n",
    "    \n",
    "    def extract_files_and_functions_info(self, patch_text):\n",
    "        \"\"\"Extract the file paths and function names that contain added or deleted lines from a diff.\"\"\"\n",
    "        function_pattern = re.compile(r'^@@.*?@@\\s*(\\w[\\w\\s\\*]*)\\(')\n",
    "        file_path_pattern = re.compile(r'^diff --git a/(.*?) b/')\n",
    "\n",
    "        files_info = {}\n",
    "        current_function = None\n",
    "        current_file_path = None\n",
    "        current_added_block = []\n",
    "        current_deleted_block = []\n",
    "        lines = patch_text.split('\\n')\n",
    "\n",
    "        for line in lines:\n",
    "            file_match = file_path_pattern.search(line)\n",
    "            if file_match:\n",
    "                current_file_path = file_match.group(1).strip()\n",
    "                if current_file_path not in files_info:\n",
    "                    files_info[current_file_path] = {'functions': {}}\n",
    "                current_function = None  # reset when encountering a new file path\n",
    "                continue\n",
    "\n",
    "            match = function_pattern.search(line)\n",
    "            if match:\n",
    "                current_function = match.group(1).strip()\n",
    "                if current_function not in files_info[current_file_path]['functions']:\n",
    "                    files_info[current_file_path]['functions'][current_function] = {'added': [], 'deleted': []}\n",
    "                # Clear the current blocks when a new function is found\n",
    "                current_added_block = []\n",
    "                current_deleted_block = []\n",
    "            else:\n",
    "                if current_file_path:\n",
    "                    if line.startswith('+') and not line.startswith('+++'):\n",
    "                        if current_deleted_block:\n",
    "                            if current_function:\n",
    "                                files_info[current_file_path]['functions'][current_function]['deleted'].append('\\n'.join(current_deleted_block))\n",
    "                            else:\n",
    "                                files_info[current_file_path].setdefault('deleted', []).append('\\n'.join(current_deleted_block))\n",
    "                            current_deleted_block = []\n",
    "                        current_added_block.append(line[1:].strip())\n",
    "                    elif line.startswith('-') and not line.startswith('---'):\n",
    "                        if current_added_block:\n",
    "                            if current_function:\n",
    "                                files_info[current_file_path]['functions'][current_function]['added'].append('\\n'.join(current_added_block))\n",
    "                            else:\n",
    "                                files_info[current_file_path].setdefault('added', []).append('\\n'.join(current_added_block))\n",
    "                            current_added_block = []\n",
    "                        current_deleted_block.append(line[1:].strip())\n",
    "                    else:\n",
    "                        if current_added_block:\n",
    "                            if current_function:\n",
    "                                files_info[current_file_path]['functions'][current_function]['added'].append('\\n'.join(current_added_block))\n",
    "                            else:\n",
    "                                files_info[current_file_path].setdefault('added', []).append('\\n'.join(current_added_block))\n",
    "                            current_added_block = []\n",
    "                        if current_deleted_block:\n",
    "                            if current_function:\n",
    "                                files_info[current_file_path]['functions'][current_function]['deleted'].append('\\n'.join(current_deleted_block))\n",
    "                            else:\n",
    "                                files_info[current_file_path].setdefault('deleted', []).append('\\n'.join(current_deleted_block))\n",
    "                            current_deleted_block = []\n",
    "\n",
    "        # Append any remaining blocks\n",
    "        if current_added_block:\n",
    "            if current_function:\n",
    "                files_info[current_file_path]['functions'][current_function]['added'].append('\\n'.join(current_added_block))\n",
    "            else:\n",
    "                files_info[current_file_path].setdefault('added', []).append('\\n'.join(current_added_block))\n",
    "        if current_deleted_block:\n",
    "            if current_function:\n",
    "                files_info[current_file_path]['functions'][current_function]['deleted'].append('\\n'.join(current_deleted_block))\n",
    "            else:\n",
    "                files_info[current_file_path].setdefault('deleted', []).append('\\n'.join(current_deleted_block))\n",
    "\n",
    "        # Clean up empty strings\n",
    "        for file_path, changes in files_info.items():\n",
    "            if 'added' in changes:\n",
    "                changes['added'] = list(filter(None, changes['added']))\n",
    "            if 'deleted' in changes:\n",
    "                changes['deleted'] = list(filter(None, changes['deleted']))\n",
    "            for function_name, function_changes in list(changes['functions'].items()):\n",
    "                function_changes['added'] = list(filter(None, function_changes['added']))\n",
    "                function_changes['deleted'] = list(filter(None, function_changes['deleted']))\n",
    "                if not function_name:\n",
    "                    del changes['functions'][function_name]\n",
    "\n",
    "        return files_info\n",
    "\n",
    "    def extract_function(self, code, function_name):\n",
    "        \"\"\"Extract the entire function (vulnerable or patched) by its name.\"\"\"\n",
    "        if not isinstance(code, str):\n",
    "            return None\n",
    "\n",
    "        # Pattern to match the function start\n",
    "        function_start_pattern = re.compile(r'\\b{}\\b\\s*\\([^{{}}]*\\)\\s*{{'.format(re.escape(function_name)), re.DOTALL)\n",
    "        match = function_start_pattern.search(code)\n",
    "        if not match:\n",
    "            return None\n",
    "\n",
    "        start_index = match.start()\n",
    "        brace_stack = []\n",
    "        inside_function = False\n",
    "        end_index = start_index\n",
    "\n",
    "        for i in range(start_index, len(code)):\n",
    "            if code[i] == '{':\n",
    "                brace_stack.append('{')\n",
    "                inside_function = True\n",
    "            elif code[i] == '}':\n",
    "                if brace_stack:\n",
    "                    brace_stack.pop()\n",
    "                    if not brace_stack:\n",
    "                        end_index = i + 1\n",
    "                        break\n",
    "\n",
    "        if not inside_function or brace_stack:\n",
    "            return None\n",
    "\n",
    "        return code[start_index:end_index]\n",
    "\n",
    "    def is_change_within_function(self, function, changes):\n",
    "        \"\"\"Check if any change block is present within the given function code.\"\"\"\n",
    "        function_lines = function.split('\\n')\n",
    "        change_blocks = changes['added'] + changes['deleted']\n",
    "\n",
    "        for change in change_blocks:\n",
    "            change_lines = [line.strip() for line in change.split('\\n') if line.strip()]\n",
    "            if not change_lines:\n",
    "                continue\n",
    "\n",
    "            for i in range(len(function_lines) - len(change_lines) + 1):\n",
    "                if all(change_lines[j] == function_lines[i + j].strip() for j in range(len(change_lines))):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    def parase_patch_header(self, patch_text):\n",
    "        \"\"\"Parse the patch header to extract the number of files changed, added, and deleted lines.\"\"\"\n",
    "        added_lines = 0\n",
    "        deleted_lines = 0\n",
    "        files_changed = set()\n",
    "\n",
    "        file_pattern = re.compile(r'^diff --git a/(.*?) b/(.*?)$', re.MULTILINE)\n",
    "        matches = file_pattern.findall(patch_text)\n",
    "        for match in matches:\n",
    "            files_changed.add(match[0])\n",
    "\n",
    "        sections = re.split(r'(?m)^diff --git', patch_text)\n",
    "        for section in sections[1:]:\n",
    "            lines = section.split('\\n')\n",
    "            for line in lines:\n",
    "                if line.startswith('+') and not line.startswith('+++'):\n",
    "                    added_lines += 1\n",
    "                elif line.startswith('-') and not line.startswith('---'):\n",
    "                    deleted_lines += 1\n",
    "\n",
    "        return len(files_changed), added_lines, deleted_lines\n",
    "\n",
    "    def extract_commit_description(self, commit_hash):\n",
    "        \"\"\"Extract the commit description using git log.\"\"\"\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                ['git', '-C', self.repo_path, 'log', '--format=%B', '-n', '1', commit_hash],\n",
    "                stdout=subprocess.PIPE,\n",
    "                text=True,\n",
    "                encoding='utf-8'\n",
    "            )\n",
    "            return result.stdout.strip()\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error extracting description for commit {commit_hash}\")\n",
    "            print(e.output)\n",
    "            return None\n",
    "\n",
    "    def build_code_blocks(self, files_info, commit_hash):\n",
    "        \"\"\"Build the vulnerable and patched code blocks from the patch info.\"\"\"\n",
    "        vulnerable_code_block = \"\"\n",
    "        patched_code_block = \"\"\n",
    "\n",
    "        # Process file-level changes\n",
    "        for file_path, file_changes in files_info.items():\n",
    "            file_header_printed_vulnerable = False\n",
    "            file_header_printed_patched = False\n",
    "\n",
    "            # Process function-level changes\n",
    "            functions_to_modify = []\n",
    "            for function_name, changes in file_changes['functions'].items():\n",
    "                if not function_name:\n",
    "                    continue\n",
    "                vulnerable_code = self.fetch_pre_fix_vulnerable_code(commit_hash, file_path)\n",
    "                patched_code = self.fetch_fixed_code(commit_hash, file_path)\n",
    "\n",
    "                vulnerable_function = self.extract_function(vulnerable_code, function_name)\n",
    "                patched_function = self.extract_function(patched_code, function_name)\n",
    "\n",
    "                # Check if the change appears within the function body\n",
    "                if vulnerable_function and patched_function:\n",
    "                    if (self.is_change_within_function(vulnerable_function, changes) or\n",
    "                        self.is_change_within_function(patched_function, changes)):\n",
    "                        if not file_header_printed_vulnerable:\n",
    "                            vulnerable_code_block += f\"// File path: {file_path}\\n\"\n",
    "                            file_header_printed_vulnerable = True\n",
    "                        if not file_header_printed_patched:\n",
    "                            patched_code_block += f\"// File path: {file_path}\\n\"\n",
    "                            file_header_printed_patched = True\n",
    "                        vulnerable_code_block += f\"{vulnerable_function}\\n\"\n",
    "                        patched_code_block += f\"{patched_function}\\n\"\n",
    "                    else:\n",
    "                        # Look for function signatures in the added/deleted lines\n",
    "                        pattern = r'\\b([a-zA-Z_][a-zA-Z0-9_\\* ]*\\s+[a-zA-Z_][a-zA-Z0-9_]*)\\s*\\([^)]*\\)'\n",
    "                        added_function_signatures = re.findall(pattern, '\\n'.join(changes['added']), re.MULTILINE)\n",
    "                        deleted_function_signatures = re.findall(pattern, '\\n'.join(changes['deleted']), re.MULTILINE)\n",
    "                        if added_function_signatures or deleted_function_signatures:\n",
    "                            new_function_name = added_function_signatures[0] if added_function_signatures else deleted_function_signatures[0]\n",
    "                            functions_to_modify.append((function_name, new_function_name))\n",
    "                        else:\n",
    "                            functions_to_modify.append((function_name, \"\"))\n",
    "                else:\n",
    "                    if changes.get('added'):\n",
    "                        sigs = self.extract_function_signatures('\\n'.join(changes['added']))\n",
    "                        if sigs:\n",
    "                            new_function_name = sigs[0]\n",
    "                            functions_to_modify.append((function_name, new_function_name))\n",
    "                            patched_function = self.extract_function(patched_code, new_function_name)\n",
    "                        else:\n",
    "                            patched_function = '\\n'.join(changes['added'])\n",
    "                            functions_to_modify.append((function_name, \"\"))\n",
    "                        if not file_header_printed_patched:\n",
    "                            patched_code_block += f\"// File path: {file_path}\\n\"\n",
    "                            file_header_printed_patched = True\n",
    "                        patched_code_block += f\"{patched_function}\\n\"\n",
    "\n",
    "                    if changes.get('deleted'):\n",
    "                        sigs = self.extract_function_signatures('\\n'.join(changes['deleted']))\n",
    "                        if sigs:\n",
    "                            new_function_name = sigs[0]\n",
    "                            functions_to_modify.append((function_name, new_function_name))\n",
    "                            vulnerable_function = self.extract_function(vulnerable_code, new_function_name)\n",
    "                        else:\n",
    "                            vulnerable_function = '\\n'.join(changes['deleted'])\n",
    "                            functions_to_modify.append((function_name, \"\"))\n",
    "                        if not file_header_printed_vulnerable:\n",
    "                            vulnerable_code_block += f\"// File path: {file_path}\\n\"\n",
    "                            file_header_printed_vulnerable = True\n",
    "                        vulnerable_code_block += f\"{vulnerable_function}\\n\"\n",
    "\n",
    "            # Process any functions that were marked for modification\n",
    "            functions_to_modify = list(set(functions_to_modify))\n",
    "            for function_name, new_function_name in functions_to_modify:\n",
    "                if not function_name:\n",
    "                    continue\n",
    "                if new_function_name in file_changes['functions']:\n",
    "                    combine_add = file_changes['functions'][function_name]['added'] + file_changes['functions'][new_function_name]['added']\n",
    "                    combine_del = file_changes['functions'][function_name]['deleted'] + file_changes['functions'][new_function_name]['deleted']\n",
    "                    file_changes['functions'][new_function_name] = {'added': combine_add, 'deleted': combine_del}\n",
    "                    del file_changes['functions'][function_name]\n",
    "                else:\n",
    "                    original_value = file_changes['functions'][function_name]\n",
    "                    del file_changes['functions'][function_name]\n",
    "                    file_changes['functions'][new_function_name] = original_value\n",
    "\n",
    "                if not new_function_name:\n",
    "                    continue\n",
    "                if new_function_name in vulnerable_code_block or new_function_name in patched_code_block:\n",
    "                    continue\n",
    "                vulnerable_code = self.fetch_pre_fix_vulnerable_code(commit_hash, file_path)\n",
    "                patched_code = self.fetch_fixed_code(commit_hash, file_path)\n",
    "                vulnerable_function = self.extract_function(vulnerable_code, new_function_name)\n",
    "                patched_function = self.extract_function(patched_code, new_function_name)\n",
    "                if vulnerable_function or patched_function:\n",
    "                    if not file_header_printed_vulnerable:\n",
    "                        vulnerable_code_block += f\"// File path: {file_path}\\n\"\n",
    "                        file_header_printed_vulnerable = True\n",
    "                    if not file_header_printed_patched:\n",
    "                        patched_code_block += f\"// File path: {file_path}\\n\"\n",
    "                        file_header_printed_patched = True\n",
    "                    vulnerable_code_block += f\"{vulnerable_function}\\n\"\n",
    "                    patched_code_block += f\"{patched_function}\\n\"\n",
    "\n",
    "            # Handle file-level added/deleted lines if present\n",
    "            if file_changes.get('added'):\n",
    "                if not file_header_printed_patched:\n",
    "                    patched_code_block += f\"// File path: {file_path}\\n\"\n",
    "                    file_header_printed_patched = True\n",
    "                patched_code_block += f\"{''.join(file_changes['added'])}\\n\"\n",
    "\n",
    "            if file_changes.get('deleted'):\n",
    "                if not file_header_printed_vulnerable:\n",
    "                    vulnerable_code_block += f\"// File path: {file_path}\\n\"\n",
    "                    file_header_printed_vulnerable = True\n",
    "                vulnerable_code_block += f\"{''.join(file_changes['deleted'])}\\n\"\n",
    "\n",
    "        return vulnerable_code_block, patched_code_block\n",
    "\n",
    "    def num_functions_changed(self, vulnerable_code_block, patched_code_block):\n",
    "        \"\"\"Calculate the number of functions changed between the two code blocks.\"\"\"\n",
    "        vulnerable_functions = self.extract_function_signatures(vulnerable_code_block)\n",
    "        patched_functions = self.extract_function_signatures(patched_code_block)\n",
    "        unique_functions = set(vulnerable_functions + patched_functions)\n",
    "        return len(unique_functions)\n",
    "\n",
    "def main():\n",
    "\n",
    "    repo_path = \"/home/azibaeir/Research/Benchmarking/gecko-dev\"  # e.g., \"/home/user/gecko-dev\"\n",
    "    commit_hash = \"d3fc632669c98bc8a94c820be75455ca4b446cf7\"\n",
    "\n",
    "    git_interaction = GitInteraction(repo_path)\n",
    "    patch_text = git_interaction.get_patch_of_commit(commit_hash)\n",
    "    if not patch_text:\n",
    "        print(\"Failed to retrieve patch.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    files_info = git_interaction.extract_files_and_functions_info(patch_text)\n",
    "    vulnerable_code_block, patched_code_block = git_interaction.build_code_blocks(files_info, commit_hash)\n",
    "\n",
    "    print(\"Vulnerable code block:\")\n",
    "    print(vulnerable_code_block)\n",
    "    print(\"\\nPatched code block:\")\n",
    "    print(patched_code_block)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre&curr-commit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fetch pre-commit and current version of a file\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def get_changed_files(repo_path, commit_hash):\n",
    "    \"\"\"\n",
    "    Use git diff-tree to list all files changed in the given commit.\n",
    "    \"\"\"\n",
    "    cmd = [\"git\", \"diff-tree\", \"--no-commit-id\", \"--name-only\", \"-r\", commit_hash]\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            cmd, cwd=repo_path, text=True, capture_output=True, check=True\n",
    "        )\n",
    "        # Each line is a file path.\n",
    "        files = result.stdout.splitlines()\n",
    "        return files\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[ERROR] Failed to get changed files: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def get_precommit_file(repo_path, commit_hash, file_path):\n",
    "    \"\"\"\n",
    "    Retrieve the content of the file at the parent of the commit (i.e. the precommit version).\n",
    "    \"\"\"\n",
    "    # Note: using f\"{commit_hash}^\" to indicate the parent commit.\n",
    "    cmd = [\"git\", \"show\", f\"{commit_hash}^:{file_path}\"]\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            cmd, cwd=repo_path, text=True, capture_output=True, check=True\n",
    "        )\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[ERROR] Failed to get precommit version of {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_current_file(repo_path, commit_hash, file_path):\n",
    "    \"\"\"\n",
    "    Retrieve the content of the file at the commit (i.e. the current commit version).\n",
    "    \"\"\"\n",
    "    cmd = [\"git\", \"show\", f\"{commit_hash}:{file_path}\"]\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            cmd, cwd=repo_path, text=True, capture_output=True, check=True\n",
    "        )\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[ERROR] Failed to get current version of {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # --- Configuration ---\n",
    "    # Update this path to your local repository clone.\n",
    "    repo_path = \"/home/azibaeir/Research/Benchmarking/gecko-dev\"  # e.g., \"/home/user/gecko-dev\"\n",
    "    commit_hash = \"b59073dc8fae65cd9dc81c0137b0f7a9911873e2\"\n",
    "\n",
    "    if not os.path.isdir(repo_path):\n",
    "        print(f\"[ERROR] Repository path not found: {repo_path}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Get list of changed files for the commit.\n",
    "    changed_files = get_changed_files(repo_path, commit_hash)\n",
    "    if not changed_files:\n",
    "        print(\"No changed files found for this commit.\")\n",
    "        return\n",
    "\n",
    "    # For each changed file, fetch and print both the precommit and current versions.\n",
    "    for file_path in changed_files:\n",
    "        print(f\"========== Precommit version of file: {file_path} ==========\")\n",
    "        pre_content = get_precommit_file(repo_path, commit_hash, file_path)\n",
    "        if pre_content is not None:\n",
    "            # Save precommit content to a file\n",
    "            pre_filename = f\"{commit_hash}_pre_{os.path.basename(file_path)}\"\n",
    "            with open(pre_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(pre_content)\n",
    "            # print(pre_content)\n",
    "        else:\n",
    "            print(f\"[WARNING] Could not retrieve precommit content for {file_path}\")\n",
    "        \n",
    "        print(f\"========== Current version of file: {file_path} ==========\")\n",
    "        curr_content = get_current_file(repo_path, commit_hash, file_path)\n",
    "        if curr_content is not None:\n",
    "            # Save current commit content to a file\n",
    "            curr_filename = f\"{commit_hash}_curr_{os.path.basename(file_path)}\"\n",
    "            with open(curr_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(curr_content)\n",
    "            # print(curr_content)\n",
    "        else:\n",
    "            print(f\"[WARNING] Could not retrieve current content for {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "#  pre&curr-commit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all of the code except code blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "import requests\n",
    "import platform\n",
    "import clang.cindex\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Configure libclang path based on OS\n",
    "if platform.system() == \"Darwin\":\n",
    "    clang.cindex.Config.set_library_file(\"/Applications/Xcode.app/Contents/Frameworks/libclang.dylib\")\n",
    "elif platform.system() == \"Linux\":\n",
    "    possible_paths = [\n",
    "        \"/usr/lib/llvm-11/lib/libclang.so\",\n",
    "        \"/usr/lib/libclang.so\",\n",
    "        \"/usr/lib/llvm/lib/libclang.so\"\n",
    "    ]\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            clang.cindex.Config.set_library_file(path)\n",
    "            break\n",
    "# -------------------------------------------------------------------\n",
    "# Function extraction routines using text-based and Clang-based methods\n",
    "\n",
    "def find_function(source_code, function_name, class_name=None, filename=None):\n",
    "    \"\"\"\n",
    "    Find a function definition in the given source code using two methods:\n",
    "      1. Text-based parsing (suitable for many C files)\n",
    "      2. Clang-based parsing (better for C++ files)\n",
    "    \n",
    "    The function first attempts to locate the function using text parsing.\n",
    "    If that fails, it falls back to a Clang-based approach.\n",
    "    \n",
    "    Parameters:\n",
    "        source_code (str): The source code to search.\n",
    "        function_name (str): The name of the function to find.\n",
    "        class_name (str, optional): If searching for a class member, provide the class name.\n",
    "        filename (str, optional): Filename hint for Clang parsing (default is \"temp.cpp\").\n",
    "    \n",
    "    Returns:\n",
    "        str or None: The full function definition if found; otherwise, None.\n",
    "    \"\"\"\n",
    "    # --- Text-based parsing ---\n",
    "    lines = source_code.split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        if function_name in line and '(' in line and not line.strip().startswith('//'):\n",
    "            words = line.strip().split()\n",
    "            if function_name in words or f\"{function_name}(\" in line:\n",
    "                print(f\"[DEBUG] Found potential function definition (text): {line.strip()}\")\n",
    "                brace_count = 0\n",
    "                start_line = i\n",
    "                found_opening = False\n",
    "                # Try to adjust for multi-line definitions\n",
    "                while start_line > 0 and not lines[start_line - 1].strip().endswith(';'):\n",
    "                    start_line -= 1\n",
    "                    if lines[start_line].strip().startswith('/*') or lines[start_line].strip().startswith('*'):\n",
    "                        continue\n",
    "                    if lines[start_line].strip():\n",
    "                        break\n",
    "                function_lines = []\n",
    "                for j in range(start_line, len(lines)):\n",
    "                    current_line = lines[j]\n",
    "                    function_lines.append(current_line)\n",
    "                    for char in current_line:\n",
    "                        if char == '{':\n",
    "                            found_opening = True\n",
    "                            brace_count += 1\n",
    "                        elif char == '}':\n",
    "                            brace_count -= 1\n",
    "                    if found_opening and brace_count == 0:\n",
    "                        return '\\n'.join(function_lines)\n",
    "    \n",
    "    # --- Clang-based parsing ---\n",
    "    import clang.cindex\n",
    "    index = clang.cindex.Index.create()\n",
    "    args = [\n",
    "        \"-x\", \"c++\",\n",
    "        \"--std=c++11\",\n",
    "        \"-fparse-all-comments\",\n",
    "        \"-I/usr/include\",\n",
    "        \"-I/usr/local/include\",\n",
    "        \"-I.\",\n",
    "        \"-DMOZILLA_INTERNAL_API\",\n",
    "        \"-DNDEBUG\",\n",
    "        \"-DTRIMMED\"\n",
    "    ]\n",
    "    try:\n",
    "        tu = index.parse(\n",
    "            filename or \"temp.cpp\",\n",
    "            args=args,\n",
    "            unsaved_files=[(filename or \"temp.cpp\", source_code)],\n",
    "            options=clang.cindex.TranslationUnit.PARSE_SKIP_FUNCTION_BODIES\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Clang failed to parse {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not tu:\n",
    "        print(\"[ERROR] Failed to create translation unit\")\n",
    "        return None\n",
    "\n",
    "    for diag in tu.diagnostics:\n",
    "        if diag.severity >= clang.cindex.Diagnostic.Warning:\n",
    "            severity = {2: \"Warning\", 3: \"Error\", 4: \"Fatal\"}.get(diag.severity, \"Unknown\")\n",
    "            print(f\"[{severity}] {diag.spelling}\")\n",
    "\n",
    "    # Use a simple line search in the source as a fallback after Clang parsing\n",
    "    for line in source_code.split('\\n'):\n",
    "        if class_name:\n",
    "            search_pattern = f\"{class_name}::{function_name}\"\n",
    "        else:\n",
    "            words = line.split()\n",
    "            if function_name in words and '(' in line:\n",
    "                search_pattern = function_name\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if search_pattern in line:\n",
    "            print(f\"[DEBUG] Found potential function definition (clang): {line.strip()}\")\n",
    "            start_idx = source_code.find(line)\n",
    "            if start_idx != -1:\n",
    "                brace_count = 0\n",
    "                end_idx = start_idx\n",
    "                found_opening = False\n",
    "                for i in range(start_idx, len(source_code)):\n",
    "                    if source_code[i] == '{':\n",
    "                        found_opening = True\n",
    "                        brace_count += 1\n",
    "                    elif source_code[i] == '}':\n",
    "                        brace_count -= 1\n",
    "                        if found_opening and brace_count == 0:\n",
    "                            end_idx = i + 1\n",
    "                            break\n",
    "                if end_idx > start_idx:\n",
    "                    return source_code[start_idx:end_idx]\n",
    "    return None\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Extract function names from a patch/diff file.\n",
    "\n",
    "def extract_functions_from_patch(patch_content):\n",
    "    \"\"\"\n",
    "    Extract all function names from a patch/diff file where changes (+ or -) occurred.\n",
    "    Returns a list of tuples (function_name, class_name).\n",
    "    \"\"\"\n",
    "    lines = patch_content.split('\\n')\n",
    "    current_function = None\n",
    "    current_class = None\n",
    "    in_function = False\n",
    "    functions = []\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        stripped_line = line.strip()\n",
    "        \n",
    "        # Handle @@ context lines\n",
    "        if line.startswith('@@'):\n",
    "            in_function = False\n",
    "            current_function = None\n",
    "            current_class = None\n",
    "            \n",
    "            if '@@ ' in line:\n",
    "                context_part = line.split('@@ ')[-1].strip()\n",
    "                if '::' in context_part:\n",
    "                    parts = context_part.split('::')\n",
    "                    current_class = parts[0].strip().replace('@', '').strip()\n",
    "                    current_function = parts[1].split('(')[0].strip()\n",
    "                    in_function = True\n",
    "                else:\n",
    "                    parts = context_part.split('(')\n",
    "                    if len(parts) > 1:\n",
    "                        func_parts = parts[0].split()\n",
    "                        if func_parts:\n",
    "                            current_function = func_parts[-1].strip()\n",
    "                            current_class = None\n",
    "                            in_function = True\n",
    "\n",
    "        if not in_function:\n",
    "            if '::' in stripped_line and '(' in stripped_line and not stripped_line.startswith(('+', '-', '//', '@')):\n",
    "                parts = stripped_line.split('::')\n",
    "                if len(parts) == 2:\n",
    "                    current_class = parts[0].strip()\n",
    "                    current_function = parts[1].split('(')[0].strip()\n",
    "                    in_function = True\n",
    "            elif '(' in stripped_line and not stripped_line.startswith(('+', '-', '//', '@', '}')):\n",
    "                parts = stripped_line.split('(')[0].strip().split()\n",
    "                if parts and not parts[0] in ['if', 'while', 'for', 'switch', 'return']:\n",
    "                    current_function = parts[-1]\n",
    "                    current_class = None\n",
    "                    in_function = True\n",
    "        \n",
    "        if in_function and line.startswith(('+', '-')) and not line.startswith(('+++ ', '--- ')):\n",
    "            if current_class and '@' in current_class:\n",
    "                current_class = current_class.split('@')[-1].strip()\n",
    "            current = (current_function, current_class)\n",
    "            if current not in functions:\n",
    "                functions.append(current)\n",
    "    print(f\"functions: {functions}\")\n",
    "    return functions\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Git interaction routines\n",
    "\n",
    "def get_patch(repo_path, commit_hash):\n",
    "    \"\"\"\n",
    "    Retrieve the full patch (diff) for the given commit.\n",
    "    \"\"\"\n",
    "    cmd = [\"git\", \"show\", commit_hash]\n",
    "    try:\n",
    "        result = subprocess.run(cmd, cwd=repo_path, text=True, capture_output=True, check=True)\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[ERROR] Failed to get patch for commit {commit_hash}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_changed_files(repo_path, commit_hash):\n",
    "    \"\"\"\n",
    "    Use git diff-tree to list all files changed in the given commit.\n",
    "    \"\"\"\n",
    "    cmd = [\"git\", \"diff-tree\", \"--no-commit-id\", \"--name-only\", \"-r\", commit_hash]\n",
    "    try:\n",
    "        result = subprocess.run(cmd, cwd=repo_path, text=True, capture_output=True, check=True)\n",
    "        return result.stdout.splitlines()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[ERROR] Failed to get changed files: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def get_precommit_file(repo_path, commit_hash, file_path):\n",
    "    \"\"\"\n",
    "    Retrieve the content of the file at the parent of the commit (pre-commit version).\n",
    "    \"\"\"\n",
    "    cmd = [\"git\", \"show\", f\"{commit_hash}^:{file_path}\"]\n",
    "    try:\n",
    "        result = subprocess.run(cmd, cwd=repo_path, text=True, capture_output=True, check=True)\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[ERROR] Failed to get precommit version of {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_current_file(repo_path, commit_hash, file_path):\n",
    "    \"\"\"\n",
    "    Retrieve the content of the file at the commit (current version).\n",
    "    \"\"\"\n",
    "    cmd = [\"git\", \"show\", f\"{commit_hash}:{file_path}\"]\n",
    "    try:\n",
    "        result = subprocess.run(cmd, cwd=repo_path, text=True, capture_output=True, check=True)\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[ERROR] Failed to get current version of {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Main entry point\n",
    "\n",
    "def main():\n",
    "    # --- Configuration ---\n",
    "    repo_path = \"/home/azibaeir/Research/Benchmarking/gecko-dev\"  # Update as needed.\n",
    "    commit_hash = \"d3fc632669c98bc8a94c820be75455ca4b446cf7\"\n",
    "    # commit_hash = \"b59073dc8fae65cd9dc81c0137b0f7a9911873e2\"\n",
    "    # commit_hash = \"75b14a0e97e07f63ad55f41b7d978aeba31d711e\"\n",
    "    # commit_hash = \"e29d8ab4e4e47c0f84ecd43c9d100791d265f71c\"\n",
    "\n",
    "    if not os.path.isdir(repo_path):\n",
    "        print(f\"[ERROR] Repository path not found: {repo_path}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Retrieve patch content and extract function names from the patch.\n",
    "    patch_content = get_patch(repo_path, commit_hash)\n",
    "    if patch_content is None:\n",
    "        print(\"[ERROR] Could not retrieve patch content.\")\n",
    "        return\n",
    "\n",
    "    print(\"========== Extracting functions from patch ==========\")\n",
    "    functions_in_patch = extract_functions_from_patch(patch_content)\n",
    "    if functions_in_patch:\n",
    "        for func, cls in functions_in_patch:\n",
    "            if cls:\n",
    "                print(f\"Function: {func}, Class: {cls}\")\n",
    "            else:\n",
    "                print(f\"Function: {func}\")\n",
    "    else:\n",
    "        print(\"No functions extracted from patch.\")\n",
    "    print(\"=====================================================\\n\")\n",
    "\n",
    "    # Get list of changed files for this commit.\n",
    "    changed_files = get_changed_files(repo_path, commit_hash)\n",
    "    if not changed_files:\n",
    "        print(\"No changed files found for this commit.\")\n",
    "        return\n",
    "\n",
    "    # Prepare accumulators for combined code blocks.\n",
    "    combined_vulnerable_code = []\n",
    "    combined_patched_code = []\n",
    "\n",
    "    # For each changed file, fetch pre-commit and current versions,\n",
    "    # then extract the complete function definitions for each changed function.\n",
    "    for file_path in changed_files:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        pre_content = get_precommit_file(repo_path, commit_hash, file_path)\n",
    "        curr_content = get_current_file(repo_path, commit_hash, file_path)\n",
    "        \n",
    "        if pre_content is None or curr_content is None:\n",
    "            print(f\"[WARNING] Skipping file {file_path} due to missing content.\")\n",
    "            continue\n",
    "\n",
    "        # Optionally, save file contents\n",
    "        pre_filename = f\"{commit_hash}_pre_{os.path.basename(file_path)}\"\n",
    "        with open(pre_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(pre_content)\n",
    "        curr_filename = f\"{commit_hash}_curr_{os.path.basename(file_path)}\"\n",
    "        with open(curr_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(curr_content)\n",
    "\n",
    "        file_vulnerable_blocks = []\n",
    "        file_patched_blocks = []\n",
    "\n",
    "        # For each function extracted from the patch, check if it appears in the file.\n",
    "        for func_name, class_name in functions_in_patch:\n",
    "            # Check if the function name is present in at least one version.\n",
    "            if func_name not in pre_content and func_name not in curr_content:\n",
    "                continue\n",
    "\n",
    "            print(f\"  Attempting extraction for function '{func_name}'\", end=\"\")\n",
    "            if class_name:\n",
    "                print(f\" (Class: {class_name})\")\n",
    "            else:\n",
    "                print()\n",
    "\n",
    "            vulnerable_func = find_function(pre_content, func_name, class_name, filename=file_path)\n",
    "            patched_func = find_function(curr_content, func_name, class_name, filename=file_path)\n",
    "\n",
    "            if vulnerable_func:\n",
    "                file_vulnerable_blocks.append(vulnerable_func)\n",
    "            else:\n",
    "                print(f\"    [INFO] Vulnerable version of {func_name} not found in {file_path}\")\n",
    "\n",
    "            if patched_func:\n",
    "                file_patched_blocks.append(patched_func)\n",
    "            else:\n",
    "                print(f\"    [INFO] Patched version of {func_name} not found in {file_path}\")\n",
    "\n",
    "        # Combine file-level code: if functions were extracted, prepend a file header.\n",
    "        if file_vulnerable_blocks:\n",
    "            combined_vulnerable_code.append(f\"// File: {file_path}\\n\" + \"\\n\\n\".join(file_vulnerable_blocks))\n",
    "        else:\n",
    "            # If no functions, include the whole file as vulnerable code.\n",
    "            combined_vulnerable_code.append(f\"// File: {file_path}\\n\" + pre_content)\n",
    "\n",
    "        if file_patched_blocks:\n",
    "            combined_patched_code.append(f\"// File: {file_path}\\n\" + \"\\n\\n\".join(file_patched_blocks))\n",
    "        else:\n",
    "            combined_patched_code.append(f\"// File: {file_path}\\n\" + curr_content)\n",
    "\n",
    "    # Build the final combined code blocks.\n",
    "    vulnerable_code_block = \"\\n\\n\".join(combined_vulnerable_code)\n",
    "    patched_code_block = \"\\n\\n\".join(combined_patched_code)\n",
    "\n",
    "    print(\"========== Combined Vulnerable Code Block ==========\")\n",
    "    print(vulnerable_code_block)\n",
    "    print(\"=====================================================\\n\")\n",
    "    print(\"========== Combined Patched Code Block ==========\")\n",
    "    print(patched_code_block)\n",
    "    print(\"=====================================================\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "# all of the code except code blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "import sqlite3\n",
    "import platform\n",
    "import clang.cindex\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Configure libclang path based on OS\n",
    "if platform.system() == \"Darwin\":\n",
    "    clang.cindex.Config.set_library_file(\"/Applications/Xcode.app/Contents/Frameworks/libclang.dylib\")\n",
    "elif platform.system() == \"Linux\":\n",
    "    possible_paths = [\n",
    "        \"/usr/lib/llvm-11/lib/libclang.so\",\n",
    "        \"/usr/lib/libclang.so\",\n",
    "        \"/usr/lib/llvm/lib/libclang.so\"\n",
    "    ]\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            clang.cindex.Config.set_library_file(path)\n",
    "            break\n",
    "# -------------------------------------------------------------------\n",
    "# Function extraction routines using text-based and Clang-based methods\n",
    "\n",
    "def find_function(source_code, function_name, class_name=None, filename=None):\n",
    "    \"\"\"\n",
    "    Find a function definition in the given source code using text- and Clang-based parsing.\n",
    "    Returns the complete function definition if found; otherwise, None.\n",
    "    \"\"\"\n",
    "    lines = source_code.split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        if function_name in line and '(' in line and not line.strip().startswith('//'):\n",
    "            words = line.strip().split()\n",
    "            if function_name in words or f\"{function_name}(\" in line:\n",
    "                brace_count = 0\n",
    "                start_line = i\n",
    "                found_opening = False\n",
    "                while start_line > 0 and not lines[start_line - 1].strip().endswith(';'):\n",
    "                    start_line -= 1\n",
    "                    if lines[start_line].strip().startswith('/*') or lines[start_line].strip().startswith('*'):\n",
    "                        continue\n",
    "                    if lines[start_line].strip():\n",
    "                        break\n",
    "                function_lines = []\n",
    "                for j in range(start_line, len(lines)):\n",
    "                    current_line = lines[j]\n",
    "                    function_lines.append(current_line)\n",
    "                    for char in current_line:\n",
    "                        if char == '{':\n",
    "                            found_opening = True\n",
    "                            brace_count += 1\n",
    "                        elif char == '}':\n",
    "                            brace_count -= 1\n",
    "                    if found_opening and brace_count == 0:\n",
    "                        return '\\n'.join(function_lines)\n",
    "    # Fallback: Clang-based parsing\n",
    "    import clang.cindex\n",
    "    index = clang.cindex.Index.create()\n",
    "    args = [\n",
    "        \"-x\", \"c++\",\n",
    "        \"--std=c++11\",\n",
    "        \"-fparse-all-comments\",\n",
    "        \"-I/usr/include\",\n",
    "        \"-I/usr/local/include\",\n",
    "        \"-I.\",\n",
    "        \"-DMOZILLA_INTERNAL_API\",\n",
    "        \"-DNDEBUG\",\n",
    "        \"-DTRIMMED\"\n",
    "    ]\n",
    "    try:\n",
    "        tu = index.parse(filename or \"temp.cpp\",\n",
    "                         args=args,\n",
    "                         unsaved_files=[(filename or \"temp.cpp\", source_code)],\n",
    "                         options=clang.cindex.TranslationUnit.PARSE_SKIP_FUNCTION_BODIES)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Clang failed to parse {filename}: {e}\")\n",
    "        return None\n",
    "    if not tu:\n",
    "        print(\"[ERROR] Failed to create translation unit\")\n",
    "        return None\n",
    "    for diag in tu.diagnostics:\n",
    "        if diag.severity >= clang.cindex.Diagnostic.Warning:\n",
    "            severity = {2: \"Warning\", 3: \"Error\", 4: \"Fatal\"}.get(diag.severity, \"Unknown\")\n",
    "            print(f\"[{severity}] {diag.spelling}\")\n",
    "    for line in source_code.split('\\n'):\n",
    "        if class_name:\n",
    "            search_pattern = f\"{class_name}::{function_name}\"\n",
    "        else:\n",
    "            words = line.split()\n",
    "            if function_name in words and '(' in line:\n",
    "                search_pattern = function_name\n",
    "            else:\n",
    "                continue\n",
    "        if search_pattern in line:\n",
    "            start_idx = source_code.find(line)\n",
    "            if start_idx != -1:\n",
    "                brace_count = 0\n",
    "                end_idx = start_idx\n",
    "                found_opening = False\n",
    "                for i in range(start_idx, len(source_code)):\n",
    "                    if source_code[i] == '{':\n",
    "                        found_opening = True\n",
    "                        brace_count += 1\n",
    "                    elif source_code[i] == '}':\n",
    "                        brace_count -= 1\n",
    "                        if found_opening and brace_count == 0:\n",
    "                            end_idx = i + 1\n",
    "                            break\n",
    "                if end_idx > start_idx:\n",
    "                    return source_code[start_idx:end_idx]\n",
    "    return None\n",
    "\n",
    "def extract_functions_from_patch(patch_content):\n",
    "    \"\"\"\n",
    "    Extract all function names from a patch/diff file where changes occurred.\n",
    "    Returns a list of tuples (function_name, class_name).\n",
    "    \"\"\"\n",
    "    lines = patch_content.split('\\n')\n",
    "    current_function = None\n",
    "    current_class = None\n",
    "    in_function = False\n",
    "    functions = []\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        stripped_line = line.strip()\n",
    "        if line.startswith('@@'):\n",
    "            in_function = False\n",
    "            current_function = None\n",
    "            current_class = None\n",
    "            if '@@ ' in line:\n",
    "                context_part = line.split('@@ ')[-1].strip()\n",
    "                if '::' in context_part:\n",
    "                    parts = context_part.split('::')\n",
    "                    current_class = parts[0].strip().replace('@', '').strip()\n",
    "                    current_function = parts[1].split('(')[0].strip()\n",
    "                    in_function = True\n",
    "                else:\n",
    "                    parts = context_part.split('(')\n",
    "                    if len(parts) > 1:\n",
    "                        func_parts = parts[0].split()\n",
    "                        if func_parts:\n",
    "                            current_function = func_parts[-1].strip()\n",
    "                            current_class = None\n",
    "                            in_function = True\n",
    "        if not in_function:\n",
    "            if '::' in stripped_line and '(' in stripped_line and not stripped_line.startswith(('+', '-', '//', '@')):\n",
    "                parts = stripped_line.split('::')\n",
    "                if len(parts) == 2:\n",
    "                    current_class = parts[0].strip()\n",
    "                    current_function = parts[1].split('(')[0].strip()\n",
    "                    in_function = True\n",
    "            elif '(' in stripped_line and not stripped_line.startswith(('+', '-', '//', '@', '}')):\n",
    "                parts = stripped_line.split('(')[0].strip().split()\n",
    "                if parts and not parts[0] in ['if', 'while', 'for', 'switch', 'return']:\n",
    "                    current_function = parts[-1]\n",
    "                    current_class = None\n",
    "                    in_function = True\n",
    "        if in_function and line.startswith(('+', '-')) and not line.startswith(('+++ ', '--- ')):\n",
    "            if current_class and '@' in current_class:\n",
    "                current_class = current_class.split('@')[-1].strip()\n",
    "            current = (current_function, current_class)\n",
    "            if current not in functions:\n",
    "                functions.append(current)\n",
    "    return functions\n",
    "\n",
    "def get_patch(repo_path, commit_hash):\n",
    "    \"\"\"\n",
    "    Retrieve the full patch (diff) for the given commit.\n",
    "    \"\"\"\n",
    "    cmd = [\"git\", \"show\", commit_hash]\n",
    "    try:\n",
    "        result = subprocess.run(cmd, cwd=repo_path, text=True, capture_output=True, check=True, errors='replace')\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[ERROR] Failed to get patch for commit {commit_hash}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_changed_files(repo_path, commit_hash):\n",
    "    \"\"\"\n",
    "    Use git diff-tree to list all files changed in the given commit.\n",
    "    \"\"\"\n",
    "    cmd = [\"git\", \"diff-tree\", \"--no-commit-id\", \"--name-only\", \"-r\", commit_hash]\n",
    "    try:\n",
    "        result = subprocess.run(cmd, cwd=repo_path, text=True, capture_output=True, check=True, errors='replace')\n",
    "        return result.stdout.splitlines()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[ERROR] Failed to get changed files: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def get_precommit_file(repo_path, commit_hash, file_path):\n",
    "    \"\"\"\n",
    "    Retrieve the content of the file at the parent of the commit (pre-commit version).\n",
    "    \"\"\"\n",
    "    cmd = [\"git\", \"show\", f\"{commit_hash}^:{file_path}\"]\n",
    "    try:\n",
    "        result = subprocess.run(cmd, cwd=repo_path, text=True, capture_output=True, check=True, errors='replace')\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[ERROR] Failed to get precommit version of {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_current_file(repo_path, commit_hash, file_path):\n",
    "    \"\"\"\n",
    "    Retrieve the content of the file at the commit (current version).\n",
    "    \"\"\"\n",
    "    cmd = [\"git\", \"show\", f\"{commit_hash}:{file_path}\"]\n",
    "    try:\n",
    "        result = subprocess.run(cmd, cwd=repo_path, text=True, capture_output=True, check=True, errors='replace')\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[ERROR] Failed to get current version of {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Main entry point for updating code blocks in the database\n",
    "\n",
    "def main():\n",
    "    repo_path = \"/home/azibaeir/Research/Benchmarking/gecko-dev\"\n",
    "    commit_db_path = \"/home/azibaeir/Research/Benchmarking/project/vulnerability_dataset/database/database.sqlite\"\n",
    "    \n",
    "    conn = sqlite3.connect(commit_db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"UPDATE vulnerabilities SET VULNERABLE_CODE_BLOCK = '', PATCHED_CODE_BLOCK = '' WHERE PROJECT = 'mozilla'\")\n",
    "    conn.commit()\n",
    "    \n",
    "    cursor.execute(\"SELECT COMMIT_HASH FROM vulnerabilities WHERE PROJECT = 'mozilla'\")\n",
    "    commit_hashes = [row[0] for row in cursor.fetchall()]\n",
    "    print(f\"Processing {len(commit_hashes)} commit(s) in mozilla.\")\n",
    "    \n",
    "    for commit_hash in commit_hashes:\n",
    "        print(f\"\\nProcessing commit: {commit_hash}\")\n",
    "        try:\n",
    "            patch_content = get_patch(repo_path, commit_hash)\n",
    "            if patch_content is None:\n",
    "                print(f\"[ERROR] Could not retrieve patch for commit {commit_hash}\")\n",
    "                continue\n",
    "\n",
    "            functions_in_patch = extract_functions_from_patch(patch_content)\n",
    "            changed_files = get_changed_files(repo_path, commit_hash)\n",
    "            if not changed_files:\n",
    "                print(f\"[ERROR] No changed files for commit {commit_hash}\")\n",
    "                continue\n",
    "\n",
    "            combined_vulnerable_blocks = []\n",
    "            combined_patched_blocks = []\n",
    "\n",
    "            for file_path in changed_files:\n",
    "                print(f\"  Processing file: {file_path}\")\n",
    "                pre_content = get_precommit_file(repo_path, commit_hash, file_path)\n",
    "                curr_content = get_current_file(repo_path, commit_hash, file_path)\n",
    "                if pre_content is None or curr_content is None:\n",
    "                    print(f\"    [ERROR] Missing content for {file_path}, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Save file contents to temporary files.\n",
    "                pre_filename = f\"{commit_hash}_pre_{os.path.basename(file_path)}\"\n",
    "                with open(pre_filename, 'w', encoding='utf-8') as f:\n",
    "                    f.write(pre_content)\n",
    "                curr_filename = f\"{commit_hash}_curr_{os.path.basename(file_path)}\"\n",
    "                with open(curr_filename, 'w', encoding='utf-8') as f:\n",
    "                    f.write(curr_content)\n",
    "                \n",
    "                file_vulnerable_blocks = []\n",
    "                file_patched_blocks = []\n",
    "                source_extensions = (\".c\", \".cpp\", \".h\", \".hpp\", \".cc\", \".cxx\")\n",
    "                if file_path.lower().endswith(source_extensions):\n",
    "                    for func_name, class_name in functions_in_patch:\n",
    "                        if func_name not in pre_content and func_name not in curr_content:\n",
    "                            continue\n",
    "                        vuln_func = find_function(pre_content, func_name, class_name, filename=file_path)\n",
    "                        patch_func = find_function(curr_content, func_name, class_name, filename=file_path)\n",
    "                        if vuln_func:\n",
    "                            file_vulnerable_blocks.append(vuln_func)\n",
    "                        else:\n",
    "                            print(f\"      [ERROR] Vulnerable version not found for {func_name} in {file_path}\")\n",
    "                        if patch_func:\n",
    "                            file_patched_blocks.append(patch_func)\n",
    "                        else:\n",
    "                            print(f\"      [ERROR] Patched version not found for {func_name} in {file_path}\")\n",
    "                else:\n",
    "                    file_vulnerable_blocks.append(pre_content)\n",
    "                    file_patched_blocks.append(curr_content)\n",
    "                \n",
    "                combined_vulnerable_blocks.append(f\"// File: {file_path}\\n\" + \"\\n\\n\".join(file_vulnerable_blocks))\n",
    "                combined_patched_blocks.append(f\"// File: {file_path}\\n\" + \"\\n\\n\".join(file_patched_blocks))\n",
    "                \n",
    "                # Remove temporary files.\n",
    "                os.remove(pre_filename)\n",
    "                os.remove(curr_filename)\n",
    "            \n",
    "            vulnerable_code_block = \"\\n\\n\".join(combined_vulnerable_blocks)\n",
    "            patched_code_block = \"\\n\\n\".join(combined_patched_blocks)\n",
    "            \n",
    "            cursor.execute(\"\"\"\n",
    "                UPDATE vulnerabilities\n",
    "                SET VULNERABLE_CODE_BLOCK = ?,\n",
    "                    PATCHED_CODE_BLOCK = ?\n",
    "                WHERE COMMIT_HASH = ? AND PROJECT = 'mozilla'\n",
    "            \"\"\", (vulnerable_code_block, patched_code_block, commit_hash))\n",
    "            conn.commit()\n",
    "            print(f\"  Updated commit {commit_hash} with new code blocks.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Processing commit {commit_hash} failed: {e}\")\n",
    "    \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import platform\n",
    "import clang.cindex\n",
    "\n",
    "# Configure libclang path based on OS\n",
    "if platform.system() == \"Darwin\":\n",
    "    clang.cindex.Config.set_library_file(\"/Applications/Xcode.app/Contents/Frameworks/libclang.dylib\")\n",
    "elif platform.system() == \"Linux\":\n",
    "    possible_paths = [\n",
    "        \"/usr/lib/llvm-11/lib/libclang.so\",\n",
    "        \"/usr/lib/libclang.so\",\n",
    "        \"/usr/lib/llvm/lib/libclang.so\"\n",
    "    ]\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            clang.cindex.Config.set_library_file(path)\n",
    "            break\n",
    "\n",
    "class GitInteraction:\n",
    "    def __init__(self, repo_path):\n",
    "        self.repo_path = repo_path\n",
    "\n",
    "    def get_patch(self, commit_hash):\n",
    "        \"\"\"\n",
    "        Retrieve the full patch (diff) for the given commit.\n",
    "        \"\"\"\n",
    "        url = f\"https://github.com/mozilla/gecko-dev/commit/{commit_hash}.patch\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response.text\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching patch from URL: {url}\")\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_changed_files(repo_path, commit_hash):\n",
    "        \"\"\"\n",
    "        Use git diff-tree to list all files changed in the given commit.\n",
    "        \"\"\"\n",
    "        cmd = [\"git\", \"diff-tree\", \"--no-commit-id\", \"--name-only\", \"-r\", commit_hash]\n",
    "        try:\n",
    "            result = subprocess.run(cmd, cwd=repo_path, text=True, capture_output=True, check=True)\n",
    "            return result.stdout.splitlines()\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"[ERROR] Failed to get changed files: {e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    def get_current_file(self, commit_hash, file_path):\n",
    "        \"\"\"\n",
    "        Retrieve the content of the file at the commit (current version).\n",
    "        \"\"\"\n",
    "        cmd = [\"git\", \"show\", f\"{commit_hash}:{file_path}\"]\n",
    "        try:\n",
    "            result = subprocess.run(cmd, cwd=self.repo_path, text=True, capture_output=True, check=True)\n",
    "            return result.stdout\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"[ERROR] Failed to get current version of {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_precommit_file(self, commit_hash, file_path):\n",
    "        \"\"\"\n",
    "        Retrieve the content of the file at the parent of the commit (pre-commit version).\n",
    "        \"\"\"\n",
    "        cmd = [\"git\", \"show\", f\"{commit_hash}^:{file_path}\"]\n",
    "        try:\n",
    "            result = subprocess.run(cmd, cwd=self.repo_path, text=True, capture_output=True, check=True)\n",
    "            return result.stdout\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"[ERROR] Failed to get precommit version of {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def find_function(self, source_code, function_name, class_name=None, filename=None):\n",
    "        \"\"\"\n",
    "        Find a function definition in the given source code using two methods:\n",
    "        1. Text-based parsing (suitable for many C files)\n",
    "        2. Clang-based parsing (better for C++ files)\n",
    "        \n",
    "        The function first attempts to locate the function using text parsing.\n",
    "        If that fails, it falls back to a Clang-based approach.\n",
    "        \n",
    "        Parameters:\n",
    "            source_code (str): The source code to search.\n",
    "            function_name (str): The name of the function to find.\n",
    "            class_name (str, optional): If searching for a class member, provide the class name.\n",
    "            filename (str, optional): Filename hint for Clang parsing (default is \"temp.cpp\").\n",
    "        \n",
    "        Returns:\n",
    "            str or None: The full function definition if found; otherwise, None.\n",
    "        \"\"\"\n",
    "        # --- Text-based parsing ---\n",
    "        lines = source_code.split('\\n')\n",
    "        for i, line in enumerate(lines):\n",
    "            if function_name in line and '(' in line and not line.strip().startswith('//'):\n",
    "                words = line.strip().split()\n",
    "                if function_name in words or f\"{function_name}(\" in line:\n",
    "                    print(f\"[DEBUG] Found potential function definition (text): {line.strip()}\")\n",
    "                    brace_count = 0\n",
    "                    start_line = i\n",
    "                    found_opening = False\n",
    "                    # Try to adjust for multi-line definitions\n",
    "                    while start_line > 0 and not lines[start_line - 1].strip().endswith(';'):\n",
    "                        start_line -= 1\n",
    "                        if lines[start_line].strip().startswith('/*') or lines[start_line].strip().startswith('*'):\n",
    "                            continue\n",
    "                        if lines[start_line].strip():\n",
    "                            break\n",
    "                    function_lines = []\n",
    "                    for j in range(start_line, len(lines)):\n",
    "                        current_line = lines[j]\n",
    "                        function_lines.append(current_line)\n",
    "                        for char in current_line:\n",
    "                            if char == '{':\n",
    "                                found_opening = True\n",
    "                                brace_count += 1\n",
    "                            elif char == '}':\n",
    "                                brace_count -= 1\n",
    "                        if found_opening and brace_count == 0:\n",
    "                            return '\\n'.join(function_lines)\n",
    "        \n",
    "        # --- Clang-based parsing ---\n",
    "        import clang.cindex\n",
    "        index = clang.cindex.Index.create()\n",
    "        args = [\n",
    "            \"-x\", \"c++\",\n",
    "            \"--std=c++11\",\n",
    "            \"-fparse-all-comments\",\n",
    "            \"-I/usr/include\",\n",
    "            \"-I/usr/local/include\",\n",
    "            \"-I.\",\n",
    "            \"-DMOZILLA_INTERNAL_API\",\n",
    "            \"-DNDEBUG\",\n",
    "            \"-DTRIMMED\"\n",
    "        ]\n",
    "        try:\n",
    "            tu = index.parse(\n",
    "                filename or \"temp.cpp\",\n",
    "                args=args,\n",
    "                unsaved_files=[(filename or \"temp.cpp\", source_code)],\n",
    "                options=clang.cindex.TranslationUnit.PARSE_SKIP_FUNCTION_BODIES\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Clang failed to parse {filename}: {e}\")\n",
    "            return None\n",
    "\n",
    "        if not tu:\n",
    "            print(\"[ERROR] Failed to create translation unit\")\n",
    "            return None\n",
    "\n",
    "        for diag in tu.diagnostics:\n",
    "            if diag.severity >= clang.cindex.Diagnostic.Warning:\n",
    "                severity = {2: \"Warning\", 3: \"Error\", 4: \"Fatal\"}.get(diag.severity, \"Unknown\")\n",
    "                print(f\"[{severity}] {diag.spelling}\")\n",
    "\n",
    "        # Use a simple line search in the source as a fallback after Clang parsing\n",
    "        for line in source_code.split('\\n'):\n",
    "            if class_name:\n",
    "                search_pattern = f\"{class_name}::{function_name}\"\n",
    "            else:\n",
    "                words = line.split()\n",
    "                if function_name in words and '(' in line:\n",
    "                    search_pattern = function_name\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if search_pattern in line:\n",
    "                print(f\"[DEBUG] Found potential function definition (clang): {line.strip()}\")\n",
    "                start_idx = source_code.find(line)\n",
    "                if start_idx != -1:\n",
    "                    brace_count = 0\n",
    "                    end_idx = start_idx\n",
    "                    found_opening = False\n",
    "                    for i in range(start_idx, len(source_code)):\n",
    "                        if source_code[i] == '{':\n",
    "                            found_opening = True\n",
    "                            brace_count += 1\n",
    "                        elif source_code[i] == '}':\n",
    "                            brace_count -= 1\n",
    "                            if found_opening and brace_count == 0:\n",
    "                                end_idx = i + 1\n",
    "                                break\n",
    "                    if end_idx > start_idx:\n",
    "                        return source_code[start_idx:end_idx]\n",
    "        return None\n",
    "\n",
    "    # def extract_functions(patch_content):\n",
    "    #     \"\"\"\n",
    "    #     Extract all function names from a patch/diff file where changes (+ or -) occurred.\n",
    "    #     Returns a list of tuples (function_name, class_name).\n",
    "    #     \"\"\"\n",
    "    #     lines = patch_content.split('\\n')\n",
    "    #     current_function = None\n",
    "    #     current_class = None\n",
    "    #     in_function = False\n",
    "    #     functions = []\n",
    "        \n",
    "    #     for i, line in enumerate(lines):\n",
    "    #         stripped_line = line.strip()\n",
    "            \n",
    "    #         # Handle @@ context lines\n",
    "    #         if line.startswith('@@'):\n",
    "    #             in_function = False\n",
    "    #             current_function = None\n",
    "    #             current_class = None\n",
    "                \n",
    "    #             if '@@ ' in line:\n",
    "    #                 context_part = line.split('@@ ')[-1].strip()\n",
    "    #                 if '::' in context_part:\n",
    "    #                     parts = context_part.split('::')\n",
    "    #                     current_class = parts[0].strip().replace('@', '').strip()\n",
    "    #                     current_function = parts[1].split('(')[0].strip()\n",
    "    #                     in_function = True\n",
    "    #                 else:\n",
    "    #                     parts = context_part.split('(')\n",
    "    #                     if len(parts) > 1:\n",
    "    #                         func_parts = parts[0].split()\n",
    "    #                         if func_parts:\n",
    "    #                             current_function = func_parts[-1].strip()\n",
    "    #                             current_class = None\n",
    "    #                             in_function = True\n",
    "\n",
    "    #         if not in_function:\n",
    "    #             if '::' in stripped_line and '(' in stripped_line and not stripped_line.startswith(('+', '-', '//', '@')):\n",
    "    #                 parts = stripped_line.split('::')\n",
    "    #                 if len(parts) == 2:\n",
    "    #                     current_class = parts[0].strip()\n",
    "    #                     current_function = parts[1].split('(')[0].strip()\n",
    "    #                     in_function = True\n",
    "    #             elif '(' in stripped_line and not stripped_line.startswith(('+', '-', '//', '@', '}')):\n",
    "    #                 parts = stripped_line.split('(')[0].strip().split()\n",
    "    #                 if parts and not parts[0] in ['if', 'while', 'for', 'switch', 'return']:\n",
    "    #                     current_function = parts[-1]\n",
    "    #                     current_class = None\n",
    "    #                     in_function = True\n",
    "            \n",
    "    #         if in_function and line.startswith(('+', '-')) and not line.startswith(('+++ ', '--- ')):\n",
    "    #             if current_class and '@' in current_class:\n",
    "    #                 current_class = current_class.split('@')[-1].strip()\n",
    "    #             current = (current_function, current_class)\n",
    "    #             if current not in functions:\n",
    "    #                 functions.append(current)\n",
    "    #     print(f\"functions: {functions}\")          \n",
    "    #     return functions\n",
    "\n",
    "    def extract_functions_from_patch(self, patch_content):\n",
    "        \"\"\"\n",
    "        Extract file paths and function information from a diff.\n",
    "        For each file, returns a dictionary with keys:\n",
    "          - \"functions\": a dict mapping function names to a dict with keys:\n",
    "              - \"class\": the class name (if any)\n",
    "              - \"added\": list of added lines within that function\n",
    "              - \"deleted\": list of deleted lines within that function\n",
    "          - \"added\": file-level added lines (if any)\n",
    "          - \"deleted\": file-level deleted lines (if any)\n",
    "        \"\"\"\n",
    "        file_path_pattern = re.compile(r'^diff --git a/(.*?) b/')\n",
    "        files_info = {}\n",
    "        current_file_path = None\n",
    "        current_function = None\n",
    "        current_class = None\n",
    "        current_added_block = []\n",
    "        current_deleted_block = []\n",
    "        lines = patch_content.split('\\n')\n",
    "\n",
    "        for line in lines:\n",
    "            # Check for a file header line.\n",
    "            file_match = file_path_pattern.search(line)\n",
    "            if file_match:\n",
    "                # Flush pending blocks before switching files.\n",
    "                if current_file_path is not None:\n",
    "                    if current_added_block:\n",
    "                        if current_function:\n",
    "                            files_info[current_file_path][\"functions\"][current_function][\"added\"].append('\\n'.join(current_added_block))\n",
    "                        else:\n",
    "                            files_info[current_file_path].setdefault(\"added\", []).append('\\n'.join(current_added_block))\n",
    "                        current_added_block = []\n",
    "                    if current_deleted_block:\n",
    "                        if current_function:\n",
    "                            files_info[current_file_path][\"functions\"][current_function][\"deleted\"].append('\\n'.join(current_deleted_block))\n",
    "                        else:\n",
    "                            files_info[current_file_path].setdefault(\"deleted\", []).append('\\n'.join(current_deleted_block))\n",
    "                        current_deleted_block = []\n",
    "                current_file_path = file_match.group(1).strip()\n",
    "                if current_file_path not in files_info:\n",
    "                    files_info[current_file_path] = {\"functions\": {}, \"added\": [], \"deleted\": []}\n",
    "                current_function = None  # Reset function context on new file\n",
    "                current_class = None\n",
    "                continue\n",
    "\n",
    "            # Check for hunk header lines (starting with @@).\n",
    "            if line.startswith('@@'):\n",
    "                # Flush pending blocks from previous function.\n",
    "                if current_file_path is not None and current_added_block:\n",
    "                    if current_function:\n",
    "                        files_info[current_file_path][\"functions\"][current_function][\"added\"].append('\\n'.join(current_added_block))\n",
    "                    else:\n",
    "                        files_info[current_file_path].setdefault(\"added\", []).append('\\n'.join(current_added_block))\n",
    "                    current_added_block = []\n",
    "                if current_file_path is not None and current_deleted_block:\n",
    "                    if current_function:\n",
    "                        files_info[current_file_path][\"functions\"][current_function][\"deleted\"].append('\\n'.join(current_deleted_block))\n",
    "                    else:\n",
    "                        files_info[current_file_path].setdefault(\"deleted\", []).append('\\n'.join(current_deleted_block))\n",
    "                    current_deleted_block = []\n",
    "                # --- Use logic from extract_functions to update current_function and current_class ---\n",
    "                # Reset context:\n",
    "                current_function = None\n",
    "                current_class = None\n",
    "                in_function = False\n",
    "                if \"@@ \" in line:\n",
    "                    context_part = line.split(\"@@ \")[-1].strip()\n",
    "                    if \"::\" in context_part:\n",
    "                        parts = context_part.split(\"::\")\n",
    "                        current_class = parts[0].strip().replace(\"@\", \"\").strip()\n",
    "                        current_function = parts[1].split(\"(\")[0].strip()\n",
    "                        in_function = True\n",
    "                    else:\n",
    "                        parts = context_part.split(\"(\")\n",
    "                        if len(parts) > 1:\n",
    "                            func_parts = parts[0].split()\n",
    "                            if func_parts:\n",
    "                                current_function = func_parts[-1].strip()\n",
    "                                current_class = None\n",
    "                                in_function = True\n",
    "                # If a function was extracted, add its entry.\n",
    "                if in_function and current_file_path:\n",
    "                    if current_function not in files_info[current_file_path][\"functions\"]:\n",
    "                        files_info[current_file_path][\"functions\"][current_function] = {\n",
    "                            \"class\": current_class,\n",
    "                            \"added\": [],\n",
    "                            \"deleted\": []\n",
    "                        }\n",
    "                continue\n",
    "\n",
    "            # Process added/deleted lines.\n",
    "            if current_file_path:\n",
    "                if line.startswith('+') and not line.startswith('+++'):\n",
    "                    if current_deleted_block:\n",
    "                        if current_function:\n",
    "                            files_info[current_file_path][\"functions\"][current_function][\"deleted\"].append('\\n'.join(current_deleted_block))\n",
    "                        else:\n",
    "                            files_info[current_file_path].setdefault(\"deleted\", []).append('\\n'.join(current_deleted_block))\n",
    "                        current_deleted_block = []\n",
    "                    current_added_block.append(line[1:].strip())\n",
    "                elif line.startswith('-') and not line.startswith('---'):\n",
    "                    if current_added_block:\n",
    "                        if current_function:\n",
    "                            files_info[current_file_path][\"functions\"][current_function][\"added\"].append('\\n'.join(current_added_block))\n",
    "                        else:\n",
    "                            files_info[current_file_path].setdefault(\"added\", []).append('\\n'.join(current_added_block))\n",
    "                        current_added_block = []\n",
    "                    current_deleted_block.append(line[1:].strip())\n",
    "                else:\n",
    "                    if current_added_block:\n",
    "                        if current_function:\n",
    "                            files_info[current_file_path][\"functions\"][current_function][\"added\"].append('\\n'.join(current_added_block))\n",
    "                        else:\n",
    "                            files_info[current_file_path].setdefault(\"added\", []).append('\\n'.join(current_added_block))\n",
    "                        current_added_block = []\n",
    "                    if current_deleted_block:\n",
    "                        if current_function:\n",
    "                            files_info[current_file_path][\"functions\"][current_function][\"deleted\"].append('\\n'.join(current_deleted_block))\n",
    "                        else:\n",
    "                            files_info[current_file_path].setdefault(\"deleted\", []).append('\\n'.join(current_deleted_block))\n",
    "                        current_deleted_block = []\n",
    "\n",
    "        # Flush any remaining blocks.\n",
    "        if current_file_path:\n",
    "            if current_added_block:\n",
    "                if current_function:\n",
    "                    files_info[current_file_path][\"functions\"][current_function][\"added\"].append('\\n'.join(current_added_block))\n",
    "                else:\n",
    "                    files_info[current_file_path].setdefault(\"added\", []).append('\\n'.join(current_added_block))\n",
    "            if current_deleted_block:\n",
    "                if current_function:\n",
    "                    files_info[current_file_path][\"functions\"][current_function][\"deleted\"].append('\\n'.join(current_deleted_block))\n",
    "                else:\n",
    "                    files_info[current_file_path].setdefault(\"deleted\", []).append('\\n'.join(current_deleted_block))\n",
    "\n",
    "        # Cleanup: remove empty strings.\n",
    "        for file_path, changes in files_info.items():\n",
    "            if \"added\" in changes:\n",
    "                changes[\"added\"] = list(filter(None, changes[\"added\"]))\n",
    "            if \"deleted\" in changes:\n",
    "                changes[\"deleted\"] = list(filter(None, changes[\"deleted\"]))\n",
    "            for func_name, func_changes in changes[\"functions\"].items():\n",
    "                func_changes[\"added\"] = list(filter(None, func_changes[\"added\"]))\n",
    "                func_changes[\"deleted\"] = list(filter(None, func_changes[\"deleted\"]))\n",
    "        return files_info\n",
    "\n",
    "\n",
    "\n",
    "    def is_change_within_function(self, vulnerable_function, patched_function, changes_deleted, changes_added):\n",
    "        \"\"\"\n",
    "        Check if any of the deleted changes appear in the vulnerable function\n",
    "        or if any of the added changes appear in the patched function.\n",
    "        \"\"\"\n",
    "        vulnerable_lines = vulnerable_function.splitlines()\n",
    "        patched_lines = patched_function.splitlines()\n",
    "        \n",
    "        # Check if deleted changes exist in the vulnerable function\n",
    "        for change in changes_deleted:\n",
    "            change = change.strip()  # Ensure no leading/trailing spaces\n",
    "            for line in vulnerable_lines:\n",
    "                if change in line.strip():\n",
    "                    return True\n",
    "\n",
    "        # Check if added changes exist in the patched function\n",
    "        for change in changes_added:\n",
    "            change = change.strip()\n",
    "            for line in patched_lines:\n",
    "                if change in line.strip():\n",
    "                    return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def parase_patch_header(self, patch_text):\n",
    "        \"\"\"Parse the patch header to extract the number of files changed, added, and deleted lines.\"\"\"\n",
    "        added_lines = 0\n",
    "        deleted_lines = 0\n",
    "        files_changed = set()\n",
    "\n",
    "        file_pattern = re.compile(r'^diff --git a/(.*?) b/(.*?)$', re.MULTILINE)\n",
    "        matches = file_pattern.findall(patch_text)\n",
    "        for match in matches:\n",
    "            files_changed.add(match[0])\n",
    "\n",
    "        sections = re.split(r'(?m)^diff --git', patch_text)\n",
    "        for section in sections[1:]:\n",
    "            lines = section.split('\\n')\n",
    "            for line in lines:\n",
    "                if line.startswith('+') and not line.startswith('+++'):\n",
    "                    added_lines += 1\n",
    "                elif line.startswith('-') and not line.startswith('---'):\n",
    "                    deleted_lines += 1\n",
    "\n",
    "        return len(files_changed), added_lines, deleted_lines\n",
    "\n",
    "    def extract_commit_description(self, commit_hash):\n",
    "        \"\"\"Extract the commit description using git log.\"\"\"\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                ['git', '-C', self.repo_path, 'log', '--format=%B', '-n', '1', commit_hash],\n",
    "                stdout=subprocess.PIPE,\n",
    "                text=True,\n",
    "                encoding='utf-8'\n",
    "            )\n",
    "            return result.stdout.strip()\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error extracting description for commit {commit_hash}\")\n",
    "            print(e.output)\n",
    "            return None\n",
    "\n",
    "    def build_code_blocks(self, files_info, commit_hash):\n",
    "        \"\"\"Build the vulnerable and patched code blocks from the patch info.\"\"\"\n",
    "        vulnerable_code_block = \"\"\n",
    "        patched_code_block = \"\"\n",
    "\n",
    "        # Process file-level changes\n",
    "        for file_path, file_changes in files_info.items():\n",
    "            file_header_printed_vulnerable = False\n",
    "            file_header_printed_patched = False\n",
    "\n",
    "            # Process function-level changes\n",
    "            functions_to_modify = []\n",
    "            for function_name, changes in file_changes['functions'].items():\n",
    "                if not function_name:\n",
    "                    continue\n",
    "\n",
    "                vulnerable_code = self.get_precommit_file(commit_hash, file_path)\n",
    "                patched_code = self.get_current_file(commit_hash, file_path)\n",
    "\n",
    "                vulnerable_function = self.extract_function(vulnerable_code, function_name)\n",
    "                patched_function = self.extract_function(patched_code, function_name)\n",
    "\n",
    "                # Use our new find_function method to extract the entire function if possible\n",
    "                if vulnerable_function and patched_function:\n",
    "                    if self.is_change_within_function(vulnerable_function, patched_function,\n",
    "                                                      changes['deleted'], changes['added']):\n",
    "                        if not file_header_printed_vulnerable:\n",
    "                            vulnerable_code_block += f\"// File path: {file_path}\\n\"\n",
    "                            file_header_printed_vulnerable = True\n",
    "                        if not file_header_printed_patched:\n",
    "                            patched_code_block += f\"// File path: {file_path}\\n\"\n",
    "                            file_header_printed_patched = True\n",
    "                        vulnerable_code_block += f\"{vulnerable_function}\\n\"\n",
    "                        patched_code_block += f\"{patched_function}\\n\"\n",
    "                    else:\n",
    "                        # Look for function signatures in the added/deleted lines\n",
    "                        pattern = r'\\b([a-zA-Z_][a-zA-Z0-9_\\* ]*\\s+[a-zA-Z_][a-zA-Z0-9_]*)\\s*\\([^)]*\\)'\n",
    "                        added_function_signatures = re.findall(pattern, '\\n'.join(changes['added']), re.MULTILINE)\n",
    "                        deleted_function_signatures = re.findall(pattern, '\\n'.join(changes['deleted']), re.MULTILINE)\n",
    "                        if added_function_signatures or deleted_function_signatures:\n",
    "                            new_function_name = (added_function_signatures[0] \n",
    "                                                 if added_function_signatures \n",
    "                                                 else deleted_function_signatures[0])\n",
    "                            functions_to_modify.append((function_name, new_function_name))\n",
    "                        else:\n",
    "                            functions_to_modify.append((function_name, \"\"))\n",
    "                else:\n",
    "                    if changes.get('added'):\n",
    "                        sigs = self.extract_function_signatures('\\n'.join(changes['added']))\n",
    "                        if sigs:\n",
    "                            new_function_name = sigs[0]\n",
    "                            functions_to_modify.append((function_name, new_function_name))\n",
    "                            patched_function = self.find_function(patched_code, new_function_name)\n",
    "                        else:\n",
    "                            patched_function = '\\n'.join(changes['added'])\n",
    "                            functions_to_modify.append((function_name, \"\"))\n",
    "                        if not file_header_printed_patched:\n",
    "                            patched_code_block += f\"// File path: {file_path}\\n\"\n",
    "                            file_header_printed_patched = True\n",
    "                        patched_code_block += f\"{patched_function}\\n\"\n",
    "\n",
    "                    if changes.get('deleted'):\n",
    "                        sigs = self.extract_function_signatures('\\n'.join(changes['deleted']))\n",
    "                        if sigs:\n",
    "                            new_function_name = sigs[0]\n",
    "                            functions_to_modify.append((function_name, new_function_name))\n",
    "                            vulnerable_function = self.find_function(vulnerable_code, new_function_name)\n",
    "                        else:\n",
    "                            vulnerable_function = '\\n'.join(changes['deleted'])\n",
    "                            functions_to_modify.append((function_name, \"\"))\n",
    "                        if not file_header_printed_vulnerable:\n",
    "                            vulnerable_code_block += f\"// File path: {file_path}\\n\"\n",
    "                            file_header_printed_vulnerable = True\n",
    "                        vulnerable_code_block += f\"{vulnerable_function}\\n\"\n",
    "\n",
    "            # Process any functions that were marked for modification\n",
    "            functions_to_modify = list(set(functions_to_modify))\n",
    "            for function_name, new_function_name in functions_to_modify:\n",
    "                if not function_name:\n",
    "                    continue\n",
    "                if new_function_name in file_changes['functions']:\n",
    "                    combine_add = file_changes['functions'][function_name]['added'] + \\\n",
    "                                  file_changes['functions'][new_function_name]['added']\n",
    "                    combine_del = file_changes['functions'][function_name]['deleted'] + \\\n",
    "                                  file_changes['functions'][new_function_name]['deleted']\n",
    "                    file_changes['functions'][new_function_name] = {'added': combine_add, 'deleted': combine_del}\n",
    "                    del file_changes['functions'][function_name]\n",
    "                else:\n",
    "                    original_value = file_changes['functions'][function_name]\n",
    "                    del file_changes['functions'][function_name]\n",
    "                    file_changes['functions'][new_function_name] = original_value\n",
    "\n",
    "                if not new_function_name:\n",
    "                    continue\n",
    "                if new_function_name in vulnerable_code_block or new_function_name in patched_code_block:\n",
    "                    continue\n",
    "                vulnerable_code = self.get_precommit_file(commit_hash, file_path)\n",
    "                patched_code = self.get_current_file(commit_hash, file_path)\n",
    "                vulnerable_function = self.find_function(vulnerable_code, new_function_name)\n",
    "                patched_function = self.find_function(patched_code, new_function_name)\n",
    "                if vulnerable_function or patched_function:\n",
    "                    if not file_header_printed_vulnerable:\n",
    "                        vulnerable_code_block += f\"// File path: {file_path}\\n\"\n",
    "                        file_header_printed_vulnerable = True\n",
    "                    if not file_header_printed_patched:\n",
    "                        patched_code_block += f\"// File path: {file_path}\\n\"\n",
    "                        file_header_printed_patched = True\n",
    "                    vulnerable_code_block += f\"{vulnerable_function}\\n\"\n",
    "                    patched_code_block += f\"{patched_function}\\n\"\n",
    "\n",
    "            # Handle file-level added/deleted lines if present\n",
    "            if file_changes.get('added'):\n",
    "                if not file_header_printed_patched:\n",
    "                    patched_code_block += f\"// File path: {file_path}\\n\"\n",
    "                    file_header_printed_patched = True\n",
    "                patched_code_block += f\"{''.join(file_changes['added'])}\\n\"\n",
    "\n",
    "            if file_changes.get('deleted'):\n",
    "                if not file_header_printed_vulnerable:\n",
    "                    vulnerable_code_block += f\"// File path: {file_path}\\n\"\n",
    "                    file_header_printed_vulnerable = True\n",
    "                vulnerable_code_block += f\"{''.join(file_changes['deleted'])}\\n\"\n",
    "\n",
    "        return vulnerable_code_block, patched_code_block\n",
    "\n",
    "def main():\n",
    "    repo_path = r\"/home/azibaeir/Research/Benchmarking/gecko-dev\"\n",
    "    commit_hash = \"d3fc632669c98bc8a94c820be75455ca4b446cf7\"\n",
    "\n",
    "    git_interaction = GitInteraction(repo_path)\n",
    "    \n",
    "    # Retrieve the patch text from the remote URL.\n",
    "    patch_text = git_interaction.get_patch(commit_hash)\n",
    "    if not patch_text:\n",
    "        print(\"Failed to retrieve patch.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Get the list of changed files.\n",
    "    changed_files = GitInteraction.get_changed_files(repo_path, commit_hash)\n",
    "    print(f\"Changed files: {changed_files}\")\n",
    "    \n",
    "    # Extract functions (and file-level changes) from the patch.\n",
    "    functions_in_patch = git_interaction.extract_functions_from_patch(patch_text)\n",
    "    print(f\"Functions in patch: {functions_in_patch}\")\n",
    "    # Build the files_info dictionary expected by build_code_blocks.\n",
    "    files_info = {}\n",
    "    for file_path in changed_files:\n",
    "        files_info[file_path] = {\n",
    "            \"functions\": {},\n",
    "            \"added\": [],\n",
    "            \"deleted\": []\n",
    "        }\n",
    "        if file_path in functions_in_patch:\n",
    "            # Populate function-level changes from the patch extraction\n",
    "            for func_name, func_data in functions_in_patch[file_path][\"functions\"].items():\n",
    "                files_info[file_path][\"functions\"][func_name] = {\"added\": [], \"deleted\": []}\n",
    "            # Also include file-level added/deleted lines if present\n",
    "            files_info[file_path][\"added\"] = functions_in_patch[file_path].get(\"added\", [])\n",
    "            files_info[file_path][\"deleted\"] = functions_in_patch[file_path].get(\"deleted\", [])\n",
    "     \n",
    "    # Build the vulnerable and patched code blocks using the constructed files_info.\n",
    "    vulnerable_code_block, patched_code_block = git_interaction.build_code_blocks(files_info, commit_hash)\n",
    "\n",
    "    print(\"Vulnerable code block:\")\n",
    "    print(vulnerable_code_block)\n",
    "    print(\"\\nPatched code block:\")\n",
    "    print(patched_code_block)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import clang.cindex\n",
    "import platform\n",
    "\n",
    "# Configure libclang path based on OS\n",
    "if platform.system() == \"Darwin\":\n",
    "    clang.cindex.Config.set_library_file(\"/Applications/Xcode.app/Contents/Frameworks/libclang.dylib\")\n",
    "elif platform.system() == \"Linux\":\n",
    "    possible_paths = [\n",
    "        \"/usr/lib/llvm-11/lib/libclang.so\",\n",
    "        \"/usr/lib/libclang.so\",\n",
    "        \"/usr/lib/llvm/lib/libclang.so\"\n",
    "    ]\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            clang.cindex.Config.set_library_file(path)\n",
    "            break\n",
    "\n",
    "def find_function_by_text(source_code, function_name):\n",
    "    \"\"\"\n",
    "    Find a function using text parsing, more suitable for C files.\n",
    "    \"\"\"\n",
    "    lines = source_code.split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        # Look for the function definition\n",
    "        if function_name in line and '(' in line and not line.strip().startswith('//'):\n",
    "            # Verify it's a function definition\n",
    "            words = line.strip().split()\n",
    "            if function_name in words or f\"{function_name}(\" in line:\n",
    "                print(f\"Found potential function definition (text): {line.strip()}\")\n",
    "                \n",
    "                # Find the opening brace\n",
    "                brace_count = 0\n",
    "                start_line = i\n",
    "                found_opening = False\n",
    "                \n",
    "                # Look backwards for any function header lines\n",
    "                while start_line > 0 and not lines[start_line-1].strip().endswith(';'):\n",
    "                    start_line -= 1\n",
    "                    if lines[start_line].strip().startswith('/*') or lines[start_line].strip().startswith('*'):\n",
    "                        continue\n",
    "                    if lines[start_line].strip():\n",
    "                        break\n",
    "                \n",
    "                # Collect the function\n",
    "                function_lines = []\n",
    "                for j in range(start_line, len(lines)):\n",
    "                    current_line = lines[j]\n",
    "                    function_lines.append(current_line)\n",
    "                    \n",
    "                    # Count braces\n",
    "                    for char in current_line:\n",
    "                        if char == '{':\n",
    "                            found_opening = True\n",
    "                            brace_count += 1\n",
    "                        elif char == '}':\n",
    "                            brace_count -= 1\n",
    "                    \n",
    "                    # Check if we've found the end of the function\n",
    "                    if found_opening and brace_count == 0:\n",
    "                        return '\\n'.join(function_lines)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def find_function_by_clang(source_code, function_name, class_name=None, filename=None):\n",
    "    \"\"\"\n",
    "    Find a function using Clang parsing, better for C++ files.\n",
    "    \"\"\"\n",
    "    index = clang.cindex.Index.create()\n",
    "    \n",
    "    # Base compilation arguments\n",
    "    args = [\n",
    "        \"-x\", \"c++\",\n",
    "        \"--std=c++11\",\n",
    "        \"-fparse-all-comments\",\n",
    "        \"-I/usr/include\",\n",
    "        \"-I/usr/local/include\",\n",
    "        \"-I.\",\n",
    "        \"-DMOZILLA_INTERNAL_API\",\n",
    "        \"-DNDEBUG\",\n",
    "        \"-DTRIMMED\"\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        tu = index.parse(\n",
    "            filename or \"temp.cpp\",\n",
    "            args=args,\n",
    "            unsaved_files=[(filename or \"temp.cpp\", source_code)],\n",
    "            options=clang.cindex.TranslationUnit.PARSE_SKIP_FUNCTION_BODIES\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Clang failed to parse {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not tu:\n",
    "        print(\"[ERROR] Failed to create translation unit\")\n",
    "        return None\n",
    "\n",
    "    # Print diagnostics at severity level Warning and above\n",
    "    for diag in tu.diagnostics:\n",
    "        if diag.severity >= clang.cindex.Diagnostic.Warning:\n",
    "            severity = {\n",
    "                2: \"Warning\",\n",
    "                3: \"Error\",\n",
    "                4: \"Fatal\"\n",
    "            }.get(diag.severity, \"Unknown\")\n",
    "            print(f\"[{severity}] {diag.spelling}\")\n",
    "\n",
    "    # First try to find the function with string matching\n",
    "    for line in source_code.split('\\n'):\n",
    "        # Handle class member function\n",
    "        if class_name:\n",
    "            search_pattern = f\"{class_name}::{function_name}\"\n",
    "        else:\n",
    "            # For standalone functions, look for the function name at a word boundary\n",
    "            words = line.split()\n",
    "            if function_name in words and '(' in line:\n",
    "                search_pattern = function_name\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        if search_pattern in line:\n",
    "            print(f\"Found potential function definition (clang): {line.strip()}\")\n",
    "            start_idx = source_code.find(line)\n",
    "            if start_idx != -1:\n",
    "                # Try to capture the entire function\n",
    "                brace_count = 0\n",
    "                end_idx = start_idx\n",
    "                found_opening = False\n",
    "                \n",
    "                for i in range(start_idx, len(source_code)):\n",
    "                    if source_code[i] == '{':\n",
    "                        found_opening = True\n",
    "                        brace_count += 1\n",
    "                    elif source_code[i] == '}':\n",
    "                        brace_count -= 1\n",
    "                        if found_opening and brace_count == 0:\n",
    "                            end_idx = i + 1\n",
    "                            break\n",
    "                \n",
    "                if end_idx > start_idx:\n",
    "                    return source_code[start_idx:end_idx]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def find_function(source_code, function_name, class_name=None, filename=None):\n",
    "    \"\"\"\n",
    "    Try both Clang and text-based parsing to find the function.\n",
    "    \"\"\"\n",
    "    # Try text-based parsing first\n",
    "    func_def = find_function_by_text(source_code, function_name)\n",
    "    if func_def:\n",
    "        print(\"Found function using text-based parsing\")\n",
    "        return func_def\n",
    "\n",
    "    # If text-based parsing fails, try Clang\n",
    "    func_def = find_function_by_clang(source_code, function_name, class_name, filename)\n",
    "    if func_def:\n",
    "        print(\"Found function using Clang parsing\")\n",
    "        return func_def\n",
    "\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    test_cases = [\n",
    "\n",
    "        {\n",
    "            \"filename\": \"b59073dc8fae65cd9dc81c0137b0f7a9911873e2_curr_nsJSEnvironment.cpp\",\n",
    "            \"function_name\": \"ScriptErrorEvent\",\n",
    "            \"class_name\": \"\",\n",
    "        }\n",
    "\n",
    "    ]\n",
    "    \n",
    "    test_case = test_cases[0]\n",
    "    \n",
    "    try:\n",
    "        with open(test_case[\"filename\"], \"r\", encoding=\"utf-8\") as f:\n",
    "            source_code = f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Could not read file {test_case['filename']}: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    func_def = find_function(\n",
    "        source_code,\n",
    "        test_case[\"function_name\"],\n",
    "        test_case.get(\"class_name\"),\n",
    "        test_case[\"filename\"]\n",
    "    )\n",
    "    \n",
    "    if func_def:\n",
    "        print(\"\\n========== Found Function ==========\\n\")\n",
    "        print(func_def)\n",
    "        print(\"\\n==================================\\n\")\n",
    "    else:\n",
    "        function_desc = (f\"{test_case.get('class_name')}::{test_case['function_name']}\" \n",
    "                        if test_case.get('class_name') \n",
    "                        else test_case['function_name'])\n",
    "        print(f\"[INFO] Could not find function {function_desc} in {test_case['filename']}\")\n",
    "        print(\"\\nFirst few lines of the file:\")\n",
    "        print(\"\\n\".join(source_code.split(\"\\n\")[:10]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract function name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_functions_from_patch(patch_content):\n",
    "    \"\"\"\n",
    "    Extract all function names from a patch/diff file where changes (+ or -) occurred.\n",
    "    Returns a list of tuples (function_name, class_name).\n",
    "    \"\"\"\n",
    "    lines = patch_content.split('\\n')\n",
    "    current_function = None\n",
    "    current_class = None\n",
    "    in_function = False\n",
    "    functions = []\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        stripped_line = line.strip()\n",
    "        \n",
    "        # Handle @@ context lines\n",
    "        if line.startswith('@@'):\n",
    "            # Reset function context at new diff chunk\n",
    "            in_function = False\n",
    "            current_function = None\n",
    "            current_class = None\n",
    "\n",
    "            if '@@ ' in line:\n",
    "                context_part = line.split('@@ ')[-1].strip()\n",
    "                # New: if context starts with \"class \", extract the class declaration\n",
    "                if context_part.startswith(\"class \"):\n",
    "                    parts = context_part.split()\n",
    "                    if len(parts) >= 2:\n",
    "                        current_function = parts[1].strip()  # Extract the class name as function name\n",
    "                        current_class = None\n",
    "                        in_function = True\n",
    "                elif '::' in context_part:\n",
    "                    parts = context_part.split('::')\n",
    "                    current_class = parts[0].strip().replace('@', '').strip()\n",
    "                    current_function = parts[1].split('(')[0].strip()\n",
    "                    in_function = True\n",
    "                else:\n",
    "                    parts = context_part.split('(')\n",
    "                    if len(parts) > 1:\n",
    "                        func_parts = parts[0].split()\n",
    "                        if func_parts:\n",
    "                            current_function = func_parts[-1].strip()\n",
    "                            current_class = None\n",
    "                            in_function = True\n",
    "\n",
    "        # Look for function declaration in code\n",
    "        if not in_function:\n",
    "            if '::' in stripped_line and '(' in stripped_line and not stripped_line.startswith(('+', '-', '//', '@')):\n",
    "                # C++ member function\n",
    "                parts = stripped_line.split('::')\n",
    "                if len(parts) == 2:\n",
    "                    current_class = parts[0].strip()\n",
    "                    current_function = parts[1].split('(')[0].strip()\n",
    "                    in_function = True\n",
    "            elif '(' in stripped_line and not stripped_line.startswith(('+', '-', '//', '@', '}')):\n",
    "                # C-style function\n",
    "                parts = stripped_line.split('(')[0].strip().split()\n",
    "                if parts and not parts[0] in ['if', 'while', 'for', 'switch', 'return']:\n",
    "                    current_function = parts[-1]\n",
    "                    current_class = None\n",
    "                    in_function = True\n",
    "        \n",
    "        # If we're in a function and find a change line, add to our list if not already present\n",
    "        if in_function and line.startswith(('+', '-')) and not line.startswith(('+++ ', '--- ')):\n",
    "            # Clean up class name if it still contains @@ markers\n",
    "            if current_class and '@' in current_class:\n",
    "                current_class = current_class.split('@')[-1].strip()\n",
    "            \n",
    "            # Create tuple of current function context\n",
    "            current = (current_function, current_class)\n",
    "            \n",
    "            # Only add if not already in our list\n",
    "            if current not in functions:\n",
    "                functions.append(current)\n",
    "                \n",
    "    return functions\n",
    "\n",
    "# Test cases\n",
    "test_patches = [\n",
    "    \"\"\"\"\"\"\n",
    "]\n",
    "\n",
    "# Test both cases\n",
    "for i, patch in enumerate(test_patches, 1):\n",
    "    functions = extract_functions_from_patch(patch)\n",
    "    print(f\"\\nTest case {i}:\")\n",
    "    if functions:\n",
    "        for func_name, class_name in functions:\n",
    "            if class_name:\n",
    "                print(f\"Function name: {func_name}, Class name: {class_name}\")\n",
    "            else:\n",
    "                print(f\"Function name: {func_name}\")\n",
    "    else:\n",
    "        print(\"No functions found with changes\")\n",
    "\n",
    "# Test cases\n",
    "test_patches = [\n",
    "    # Test case 1: Function with direct declaration\n",
    "    \"\"\"diff --git a/netwerk/base/src/nsBaseChannel.cpp b/netwerk/base/src/nsBaseChannel.cpp\n",
    "@@ -253,16 +253,19 @@ void\n",
    "nsBaseChannel::HandleAsyncRedirect(nsIChannel* newChannel)\n",
    "{\n",
    "  NS_ASSERTION(!mPump, \"Shouldn't have gotten here\");\n",
    "+  PRBool doNotify = PR_TRUE;\"\"\",\n",
    "\n",
    "    # Test case 2: Function in @@ context line\n",
    "    \"\"\"diff --git a/editor/libeditor/base/nsEditor.cpp b/editor/libeditor/base/nsEditor.cpp\n",
    "@@ -3397,7 +3397,7 @@ nsEditor::FindNode(nsINode *aCurrentNode,\n",
    "    return nullptr;\n",
    "  }\n",
    "\n",
    "-  nsIContent* candidate =\n",
    "+  nsCOMPtr<nsIContent> candidate =\"\"\",\n",
    "\n",
    "    # Test case 3: Function with multiple changes\n",
    "\n",
    "\"\"\"From 7b1c513be6bdbc0552bea0c1d312507337f4e5cd Mon Sep 17 00:00:00 2001\n",
    "From: Ehsan Akhgari <ehsan@mozilla.com>\n",
    "Date: Tue, 20 Jul 2010 09:04:14 -0400\n",
    "Subject: [PATCH] Bug 580151 - Part 1: Move the increment up in case the call\n",
    " to nsIEditor::GetSelection fails and we bail out early; r=roc\n",
    "\n",
    "--HG--\n",
    "extra : rebase_source : 249cf74c6a1700b230d946793819ff6611ebbb99\n",
    "---\n",
    " editor/libeditor/text/nsTextEditRules.cpp | 12 ++++++------\n",
    " 1 file changed, 6 insertions(+), 6 deletions(-)\n",
    "\n",
    "diff --git a/editor/libeditor/text/nsTextEditRules.cpp b/editor/libeditor/text/nsTextEditRules.cpp\n",
    "index ee8e77d9717bb..56e2b655bc6db 100644\n",
    "--- a/editor/libeditor/text/nsTextEditRules.cpp\n",
    "+++ b/editor/libeditor/text/nsTextEditRules.cpp\n",
    "@@ -221,6 +221,12 @@ nsTextEditRules::BeforeEdit(PRInt32 action, nsIEditor::EDirection aDirection)\n",
    "   \n",
    "   nsAutoLockRulesSniffing lockIt(this);\n",
    "   mDidExplicitlySetInterline = PR_FALSE;\n",
    "+  if (!mActionNesting)\n",
    "+  {\n",
    "+    // let rules remember the top level action\n",
    "+    mTheAction = action;\n",
    "+  }\n",
    "+  mActionNesting++;\n",
    "   \n",
    "   // get the selection and cache the position before editing\n",
    "   nsCOMPtr<nsISelection> selection;\n",
    "@@ -230,12 +236,6 @@ nsTextEditRules::BeforeEdit(PRInt32 action, nsIEditor::EDirection aDirection)\n",
    "   selection->GetAnchorNode(getter_AddRefs(mCachedSelectionNode));\n",
    "   selection->GetAnchorOffset(&mCachedSelectionOffset);\n",
    " \n",
    "-  if (!mActionNesting)\n",
    "-  {\n",
    "-    // let rules remember the top level action\n",
    "-    mTheAction = action;\n",
    "-  }\n",
    "-  mActionNesting++;\n",
    "   return NS_OK;\n",
    " }\n",
    " \"\"\",\n",
    " \n",
    " #  Test case 4: linux\n",
    " \"\"\"From 8c34e2d63231d4bf4852bac8521883944d770fe3 Mon Sep 17 00:00:00 2001\n",
    "From: Jens Axboe <jens.axboe@oracle.com>\n",
    "Date: Tue, 17 Oct 2006 19:43:22 +0200\n",
    "Subject: [PATCH] [PATCH] Remove SUID when splicing into an inode\n",
    "\n",
    "Originally from Mark Fasheh <mark.fasheh@oracle.com>\n",
    "\n",
    "generic_file_splice_write() does not remove S_ISUID or S_ISGID. This is\n",
    "inconsistent with the way we generally write to files.\n",
    "\n",
    "Signed-off-by: Mark Fasheh <mark.fasheh@oracle.com>\n",
    "Signed-off-by: Jens Axboe <jens.axboe@oracle.com>\n",
    "---\n",
    " fs/splice.c | 19 +++++++++++++++----\n",
    " 1 file changed, 15 insertions(+), 4 deletions(-)\n",
    "\n",
    "diff --git a/fs/splice.c b/fs/splice.c\n",
    "index 68e20e65c6e114..49fb9f12993884 100644\n",
    "--- a/fs/splice.c\n",
    "+++ b/fs/splice.c\n",
    "@@ -845,6 +845,10 @@ generic_file_splice_write_nolock(struct pipe_inode_info *pipe, struct file *out,\n",
    " \tssize_t ret;\n",
    " \tint err;\n",
    " \n",
    "+\terr = remove_suid(out->f_dentry);\n",
    "+\tif (unlikely(err))\n",
    "+\t\treturn err;\n",
    "+\n",
    " \tret = __splice_from_pipe(pipe, out, ppos, len, flags, pipe_to_file);\n",
    " \tif (ret > 0) {\n",
    " \t\t*ppos += ret;\n",
    "@@ -883,12 +887,21 @@ generic_file_splice_write(struct pipe_inode_info *pipe, struct file *out,\n",
    " \t\t\t  loff_t *ppos, size_t len, unsigned int flags)\n",
    " {\n",
    " \tstruct address_space *mapping = out->f_mapping;\n",
    "+\tstruct inode *inode = mapping->host;\n",
    " \tssize_t ret;\n",
    "+\tint err;\n",
    "+\n",
    "+\terr = should_remove_suid(out->f_dentry);\n",
    "+\tif (unlikely(err)) {\n",
    "+\t\tmutex_lock(&inode->i_mutex);\n",
    "+\t\terr = __remove_suid(out->f_dentry, err);\n",
    "+\t\tmutex_unlock(&inode->i_mutex);\n",
    "+\t\tif (err)\n",
    "+\t\t\treturn err;\n",
    "+\t}\n",
    " \n",
    " \tret = splice_from_pipe(pipe, out, ppos, len, flags, pipe_to_file);\n",
    " \tif (ret > 0) {\n",
    "-\t\tstruct inode *inode = mapping->host;\n",
    "-\n",
    " \t\t*ppos += ret;\n",
    " \n",
    " \t\t/*\n",
    "@@ -896,8 +909,6 @@ generic_file_splice_write(struct pipe_inode_info *pipe, struct file *out,\n",
    " \t\t * sync it.\n",
    " \t\t */\n",
    " \t\tif (unlikely((out->f_flags & O_SYNC) || IS_SYNC(inode))) {\n",
    "-\t\t\tint err;\n",
    "-\n",
    " \t\t\tmutex_lock(&inode->i_mutex);\n",
    " \t\t\terr = generic_osync_inode(inode, mapping,\n",
    " \t\t\t\t\t\t  OSYNC_METADATA|OSYNC_DATA);\n",
    "\n",
    "\"\"\",\n",
    "# test case 5: linux\n",
    "\"\"\"From 47d439e9fb8a81a90022cfa785bf1c36c4e2aff6 Mon Sep 17 00:00:00 2001\n",
    "From: Eric Paris <eparis@redhat.com>\n",
    "Date: Fri, 7 Aug 2009 14:53:57 -0400\n",
    "Subject: [PATCH] security: define round_hint_to_min in !CONFIG_SECURITY\n",
    "\n",
    "Fix the header files to define round_hint_to_min() and to define\n",
    "mmap_min_addr_handler() in the !CONFIG_SECURITY case.\n",
    "\n",
    "Built and tested with !CONFIG_SECURITY\n",
    "\n",
    "Signed-off-by: Eric Paris <eparis@redhat.com>\n",
    "Signed-off-by: James Morris <jmorris@namei.org>\n",
    "---\n",
    " include/linux/security.h | 30 +++++++++++++++---------------\n",
    " 1 file changed, 15 insertions(+), 15 deletions(-)\n",
    "\n",
    "diff --git a/include/linux/security.h b/include/linux/security.h\n",
    "index 7b431155e392ee..57ead99d259361 100644\n",
    "--- a/include/linux/security.h\n",
    "+++ b/include/linux/security.h\n",
    "@@ -121,6 +121,21 @@ struct request_sock;\n",
    " #define LSM_UNSAFE_PTRACE\t2\n",
    " #define LSM_UNSAFE_PTRACE_CAP\t4\n",
    " \n",
    "+/*\n",
    "+ * If a hint addr is less than mmap_min_addr change hint to be as\n",
    "+ * low as possible but still greater than mmap_min_addr\n",
    "+ */\n",
    "+static inline unsigned long round_hint_to_min(unsigned long hint)\n",
    "+{\n",
    "+\thint &= PAGE_MASK;\n",
    "+\tif (((void *)hint != NULL) &&\n",
    "+\t    (hint < mmap_min_addr))\n",
    "+\t\treturn PAGE_ALIGN(mmap_min_addr);\n",
    "+\treturn hint;\n",
    "+}\n",
    "+extern int mmap_min_addr_handler(struct ctl_table *table, int write, struct file *filp,\n",
    "+\t\t\t\t void __user *buffer, size_t *lenp, loff_t *ppos);\n",
    "+\n",
    " #ifdef CONFIG_SECURITY\n",
    " \n",
    " struct security_mnt_opts {\n",
    "@@ -149,21 +164,6 @@ static inline void security_free_mnt_opts(struct security_mnt_opts *opts)\n",
    " \topts->num_mnt_opts = 0;\n",
    " }\n",
    " \n",
    "-/*\n",
    "- * If a hint addr is less than mmap_min_addr change hint to be as\n",
    "- * low as possible but still greater than mmap_min_addr\n",
    "- */\n",
    "-static inline unsigned long round_hint_to_min(unsigned long hint)\n",
    "-{\n",
    "-\thint &= PAGE_MASK;\n",
    "-\tif (((void *)hint != NULL) &&\n",
    "-\t    (hint < mmap_min_addr))\n",
    "-\t\treturn PAGE_ALIGN(mmap_min_addr);\n",
    "-\treturn hint;\n",
    "-}\n",
    "-\n",
    "-extern int mmap_min_addr_handler(struct ctl_table *table, int write, struct file *filp,\n",
    "-\t\t\t\t void __user *buffer, size_t *lenp, loff_t *ppos);\n",
    " /**\n",
    "  * struct security_operations - main security structure\n",
    "  *\n",
    "\"\"\",\n",
    "\"\"\"From b59073dc8fae65cd9dc81c0137b0f7a9911873e2 Mon Sep 17 00:00:00 2001\n",
    "From: Boris Zbarsky <bzbarsky@mit.edu>\n",
    "Date: Tue, 8 Jun 2010 15:58:26 -0400\n",
    "Subject: [PATCH] Bug 568564.  Suppress the script filename for cross-origin\n",
    " onerror events.  r=jst\n",
    "\n",
    "---\n",
    " content/base/test/test_bug461735.html | 2 +-\n",
    " dom/base/nsJSEnvironment.cpp          | 4 ++++\n",
    " 2 files changed, 5 insertions(+), 1 deletion(-)\n",
    "\n",
    "diff --git a/content/base/test/test_bug461735.html b/content/base/test/test_bug461735.html\n",
    "index 61cb4cd647663..f1956998f9120 100644\n",
    "--- a/content/base/test/test_bug461735.html\n",
    "+++ b/content/base/test/test_bug461735.html\n",
    "@@ -19,7 +19,7 @@\n",
    " <script type=\"application/javascript\">\n",
    " window.onerror = function(message, uri, line) {\n",
    "   is(message, \"Script error.\", \"Should have empty error message\");\n",
    "-  is(uri, \"http://example.com/tests/content/base/test/bug461735-post-redirect.js\", \"Unexpected error location URI\");\n",
    "+  is(uri, \"\", \"Should have empty error location URI\");\n",
    "   is(line, 0, \"Shouldn't have a line here\");\n",
    " }\n",
    " </script>\n",
    "diff --git a/dom/base/nsJSEnvironment.cpp b/dom/base/nsJSEnvironment.cpp\n",
    "index 42537280dee3e..54180a3f076d5 100644\n",
    "--- a/dom/base/nsJSEnvironment.cpp\n",
    "+++ b/dom/base/nsJSEnvironment.cpp\n",
    "@@ -475,6 +475,10 @@ class ScriptErrorEvent : public nsRunnable\n",
    "             NS_WARNING(\"Not same origin error!\");\n",
    "             errorevent.errorMsg = xoriginMsg.get();\n",
    "             errorevent.lineNr = 0;\n",
    "+            // FIXME: once the principal of the script is not tied to\n",
    "+            // the filename, we can stop using the post-redirect\n",
    "+            // filename if we want and remove this line.\n",
    "+            errorevent.fileName = nsnull;\n",
    "           }\n",
    " \n",
    "           nsEventDispatcher::Dispatch(win, presContext, &errorevent, nsnull,\"\"\"\n",
    " \n",
    "]\n",
    "\n",
    "# Test both cases\n",
    "for i, patch in enumerate(test_patches, 1):\n",
    "    functions = extract_functions_from_patch(patch)\n",
    "    print(f\"\\nTest case {i}:\")\n",
    "    if functions:\n",
    "        for func_name, class_name in functions:\n",
    "            if class_name:\n",
    "                print(f\"Function name: {func_name}, Class name: {class_name}\")\n",
    "            else:\n",
    "                print(f\"Function name: {func_name}\")\n",
    "    else:\n",
    "        print(\"No functions found with changes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test line inside function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_change_within_function(vulnerable_function, patched_function, changes_deleted, changes_added):\n",
    "    vulnerable_lines = vulnerable_function.splitlines()\n",
    "    patched_lines = patched_function.splitlines()\n",
    "    \n",
    "    # Check if deleted changes exist in the vulnerable function\n",
    "    for change in changes_deleted:\n",
    "        change = change.strip()  # Ensure no leading/trailing spaces\n",
    "        for line in vulnerable_lines:\n",
    "            if change in line.strip():  # Check if change exists in vulnerable function\n",
    "                return True\n",
    "\n",
    "    # Check if added changes exist in the patched function\n",
    "    for change in changes_added:\n",
    "        change = change.strip()\n",
    "        for line in patched_lines:\n",
    "            if change in line.strip():  # Check if change exists in patched function\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Example usage\n",
    "vulnerable_function = \"\"\"\n",
    "void\n",
    "nsBaseChannel::HandleAsyncRedirect(nsIChannel* newChannel)\n",
    "{\n",
    "  NS_ASSERTION(!mPump, \"Shouldn't have gotten here\");\n",
    "  if (NS_SUCCEEDED(mStatus)) {\n",
    "      nsresult rv = Redirect(newChannel, nsIChannelEventSink::REDIRECT_INTERNAL,\n",
    "                             PR_TRUE);\n",
    "      if (NS_FAILED(rv))\n",
    "          Cancel(rv);\n",
    "  }\n",
    "\n",
    "  mWaitingOnAsyncRedirect = PR_FALSE;\n",
    "\n",
    "  if (NS_FAILED(mStatus)) {\n",
    "    // Notify our consumer ourselves\n",
    "    mListener->OnStartRequest(this, mListenerContext);\n",
    "    mListener->OnStopRequest(this, mListenerContext, mStatus);\n",
    "    mListener = nsnull;\n",
    "    mListenerContext = nsnull;\n",
    "  }\n",
    "\n",
    "  if (mLoadGroup)\n",
    "    mLoadGroup->RemoveRequest(this, nsnull, mStatus);\n",
    "\n",
    "  // Drop notification callbacks to prevent cycles.\n",
    "  mCallbacks = nsnull;\n",
    "  CallbacksChanged();\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "patched_function = \"\"\"void\n",
    "nsBaseChannel::HandleAsyncRedirect(nsIChannel* newChannel)\n",
    "{\n",
    "  NS_ASSERTION(!mPump, \"Shouldn't have gotten here\");\n",
    "  PRBool doNotify = PR_TRUE;\n",
    "  if (NS_SUCCEEDED(mStatus)) {\n",
    "      nsresult rv = Redirect(newChannel, nsIChannelEventSink::REDIRECT_INTERNAL,\n",
    "                             PR_TRUE);\n",
    "      if (NS_FAILED(rv))\n",
    "          Cancel(rv);\n",
    "      else\n",
    "          doNotify = PR_FALSE;\n",
    "  }\n",
    "\n",
    "  mWaitingOnAsyncRedirect = PR_FALSE;\n",
    "\n",
    "  if (doNotify) {\n",
    "    // Notify our consumer ourselves\n",
    "    mListener->OnStartRequest(this, mListenerContext);\n",
    "    mListener->OnStopRequest(this, mListenerContext, mStatus);\n",
    "    mListener = nsnull;\n",
    "    mListenerContext = nsnull;\n",
    "  }\n",
    "\n",
    "  if (mLoadGroup)\n",
    "    mLoadGroup->RemoveRequest(this, nsnull, mStatus);\n",
    "\n",
    "  // Drop notification callbacks to prevent cycles.\n",
    "  mCallbacks = nsnull;\n",
    "  CallbacksChanged();\n",
    "}\"\"\"\n",
    "\n",
    "changes_deleted = [\"if (NS_FAILED(mStatus)) {\"]\n",
    "changes_added = [\"PRBool doNotify = PR_TRUE;\", \"else \\n doNotify = PR_FALSE;\", \"if (doNotify) {\"]\n",
    "\n",
    "print(is_change_within_function(vulnerable_function, patched_function, changes_deleted, changes_added))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"/home/azibaeir/Research/Benchmarking/project/vulnerability_dataset/database/database.sqlite\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Execute the query\n",
    "# cursor.execute(\"SELECT * FROM vulnerabilities_deepseek_r1_7b\")\n",
    "cursor.execute(\"SELECT * FROM vulnerabilities_llama3_1_8b\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Write the data to a CSV file with headers\n",
    "# with open(\"vulnerabilities_deepseek_r1_7b.csv\", \"w\", newline=\"\") as csvfile:\n",
    "with open(\"vulnerabilities_llama3_1_8b.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    headers = [description[0] for description in cursor.description]\n",
    "    csvwriter.writerow(headers)\n",
    "    csvwriter.writerows(rows)\n",
    "\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmserver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
