# Vulnerability Dataset Processor

A modular Python tool for processing and analyzing vulnerability datasets from Mozilla, Linux, and Xen repositories. This tool extracts vulnerability information, code changes, and provides detailed analysis of security patches for use with the VulnSage benchmarking platform.

## Project Structure

```
vulnerability_dataset/
├── config/
│   ├── __init__.py
│   └── settings.py           # Configuration settings including batch size
├── database/
│   ├── __init__.py
│   ├── db_manager.py         # Database operations
│   └── db_utils.py           # Database utilities
├── git/
│   ├── __init__.py
│   ├── git_manager_parse_LLM.py # Git operations with LLM parsing
│   └── git_utils.py          # Git utilities
├── data_processing/
│   ├── __init__.py
│   ├── cleaner.py            # Data cleaning operations
│   └── exporter.py           # Data export operations
├── llm/                      # LLM integration components
│   ├── __init__.py
│   └── [LLM modules]
├── tests/                    # Test modules
│   ├── __init__.py
│   └── [Test modules]
├── utils/
│   ├── __init__.py
│   └── logger.py             # Logging utilities
└── main.py                   # Main entry point for dataset processing
```

## Prerequisites

- Python 3.8 or higher
- Git
- Local clones of the following repositories:
  - Mozilla: [gecko-dev](https://github.com/mozilla/gecko-dev)
  - Linux: [linux](https://github.com/torvalds/linux)
  - Xen: [xen](https://github.com/xen-project/xen)

## Installation

1. Clone this repository:
```bash
git clone <repository-url>
cd vulnerability_dataset
```

2. Create and activate a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install required packages:
```bash
pip install -r requirements.txt
```

4. Set up repository paths in `config/settings.py`:
```python
REPO_PATHS = {
    'mozilla': '/path/to/gecko-dev',
    'xen': '/path/to/xen',
    'linux': '/path/to/linux'
}
```

## Usage

1. Basic usage:
```bash
python -m vulnerability_dataset.main
```

2. Programmatic usage:
```python
from vulnerability_dataset.database.db_manager import DatabaseManager
from vulnerability_dataset.git.git_manager_parse_LLM import GitManager
from vulnerability_dataset.data_processing.cleaner import DataCleaner
from vulnerability_dataset.data_processing.exporter import DataExporter

# Initialize components
db_manager = DatabaseManager()
git_manager = GitManager()
data_cleaner = DataCleaner()
data_exporter = DataExporter()

# Create and process database
db_manager.create_database()
data_cleaner.remove_duplicates()
data_exporter.export_to_csv('vulnerabilities.csv')
```

## Key Features

### Vulnerability Processing
- Processes vulnerabilities in batches for efficiency
- Extracts both vulnerable and patched code versions
- Analyzes patches to identify changed functions and files
- Handles single-line changes and complex multi-file patches

### Git Operations
- Extracts patches from repositories
- Analyzes code changes between vulnerable and patched versions
- Extracts commit descriptions and metadata
- Identifies changed functions within files

### Database Operations
- Creates and manages SQLite database for vulnerability data
- Updates code blocks with vulnerable and patched versions
- Tracks metadata about each vulnerability
- Provides statistics on processed vulnerabilities

### Data Processing
- Removes duplicate entries
- Cleans invalid or incomplete data
- Exports processed data to CSV format
- Generates statistics about the dataset

## Configuration

Key settings in `config/settings.py`:

```python
# Database settings
DB_PATH = 'path/to/database.sqlite'
DB_TIMEOUT = 20
DB_JOURNAL_MODE = "WAL"
DB_BUSY_TIMEOUT = 30000

# Repository paths
REPO_PATHS = {
    'mozilla': '/path/to/gecko-dev',
    'xen': '/path/to/xen',
    'linux': '/path/to/linux'
}

# Batch processing settings
BATCH_SIZE = 10  # Number of vulnerabilities to process in a batch
```

## Data Structure

### Input Data Format
The database stores vulnerability information with the following structure:
- `COMMIT_HASH`: Unique identifier for each commit
- `PROJECT`: Repository source (mozilla, linux, xen)
- `VULNERABLE_CODE`: Extracted vulnerable code
- `PATCHED_CODE`: Extracted patched code
- Metadata fields: files changed, functions changed, lines added/deleted

### Output Data
The processor generates:
1. SQLite database with detailed vulnerability information
2. CSV export with processed vulnerability data
3. Code blocks ready for analysis by LLM-based detection systems

## Performance Optimizations

- Batch processing for efficient handling of large datasets
- Database optimizations for concurrent access
- Caching of git operations to reduce redundant calls
- Efficient code extraction focusing on changed functions

## Integration with VulnSage

This dataset processor prepares vulnerability data for analysis by the VulnSage benchmarking platform, which evaluates LLM-based vulnerability detection capabilities across different prompting strategies and models.
