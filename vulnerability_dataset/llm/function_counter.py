import requests
from typing import Optional
import logging

logger = logging.getLogger(__name__)

class LLMFunctionCounter:
    def __init__(self, model_name: str = "deepseek-r1", base_url: str = "http://localhost:11434"):
        """
        Initialize LLM function counter using Ollama.
        
        Args:
            model_name: Name of the Ollama model to use
            base_url: Base URL for Ollama API
        """
        self.model_name = model_name
        self.base_url = base_url
        self._check_model_availability()

    def _check_model_availability(self):
        """Check if the specified model is available in Ollama."""
        try:
            response = requests.get(f"{self.base_url}/api/tags")
            if response.status_code == 200:
                models = response.json()
                if not any(model['name'] == self.model_name for model in models['models']):
                    logger.warning(f"Model {self.model_name} not found. Please ensure it's installed in Ollama.")
        except Exception as e:
            logger.error(f"Error checking Ollama model availability: {e}")

    def count_functions(self, code_block: str) -> int:
        """
        Count functions in a code block using local Ollama model.
        
        Args:
            code_block: String containing the code
            
        Returns:
            int: Number of functions identified
        """
        if not code_block or not code_block.strip():
            return 0

        try:
            # Prepare the prompt
            prompt = f"""Task: Analyze this code and list all function definitions (including methods, constructors, and destructors). 
            Only include actual function definitions, not declarations or forward declarations.
            Format your response as a numbered list with one function per line.
            
            Code to analyze:
            {code_block}

            Your response should only contain the numbered list, nothing else."""

            # Make request to Ollama
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False,
                    "temperature": 0.7
                }
            )

            if response.status_code != 200:
                logger.error(f"Error from Ollama API: {response.text}")
                return 0

            # Parse response to count functions
            response_text = response.json()['response']
            
            # Count numbered lines
            functions = [line for line in response_text.split('\n') 
                        if line.strip() and any(line.strip().startswith(f"{i}.") for i in range(1, 100))]
            
            return len(functions)

        except Exception as e:
            logger.error(f"Error counting functions with Ollama: {e}")
            return 0  # Fallback to 0 on error

    def analyze_functions(self, code_block: str) -> list:
        """
        Get detailed analysis of functions in a code block.
        
        Args:
            code_block: String containing the code
            
        Returns:
            list: List of function names and their descriptions
        """
        if not code_block or not code_block.strip():
            return []

        try:
            prompt = f"""Task: Analyze this code and list all function definitions (including methods, constructors, and destructors).
            For each function, provide:
            1. The function name
            2. A brief description of what it does
            Format your response as a list with "Function: [name]" followed by "Description: [description]" on the next line.

            Code to analyze:
            {code_block}"""

            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False,
                    "temperature": 0.7
                }
            )

            if response.status_code != 200:
                logger.error(f"Error from Ollama API: {response.text}")
                return []

            # Parse the response
            response_text = response.json()['response']
            
            # Return the function analysis
            return response_text.split('\n\n')

        except Exception as e:
            logger.error(f"Error analyzing functions with Ollama: {e}")
            return []